{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff36dd",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Configure Assessment Parameters\n",
    "\n",
    "# pylint:disable=missing-module-docstring\n",
    "# pylint:disable=g-bad-import-order\n",
    "# pylint:disable=g-wrong-blank-lines\n",
    "# pylint:disable=g-import-not-at-top\n",
    "\n",
    "# @markdown You must re-run this cell every time you make a change.\n",
    "import os\n",
    "import textwrap\n",
    "import ee\n",
    "from google.colab import auth\n",
    "\n",
    "GCP_PROJECT = ''  # @param {type:\"string\"}\n",
    "GCP_LOCATION = ''  # @param {type:\"string\"}\n",
    "GCP_BUCKET = ''  # @param {type:\"string\"}\n",
    "GCP_SERVICE_ACCOUNT = ''  # @param {type:\"string\"}\n",
    "# @markdown This is only needed if BUILDINGS_METHOD is set to \"run_model\":\n",
    "BUILDING_SEGMENTATION_MODEL_PATH = ''  # @param {type:\"string\"}\n",
    "\n",
    "# @markdown ---\n",
    "ASSESSMENT_NAME = ''  # @param {type:\"string\"}\n",
    "EVENT_DATE = ''  # @param {type:\"date\"}\n",
    "OUTPUT_DIR = ''  # @param {type:\"string\"}\n",
    "\n",
    "# @markdown ---\n",
    "BEFORE_IMAGE_0 = ''  # @param {type:\"string\"}\n",
    "BEFORE_IMAGE_1 = ''  # @param {type:\"string\"}\n",
    "BEFORE_IMAGE_2 = ''  # @param {type:\"string\"}\n",
    "BEFORE_IMAGE_3 = ''  # @param {type:\"string\"}\n",
    "BEFORE_IMAGE_4 = ''  # @param {type:\"string\"}\n",
    "BEFORE_IMAGE_5 = ''  # @param {type:\"string\"}\n",
    "BEFORE_IMAGE_6 = ''  # @param {type:\"string\"}\n",
    "BEFORE_IMAGE_7 = ''  # @param {type:\"string\"}\n",
    "BEFORE_IMAGE_8 = ''  # @param {type:\"string\"}\n",
    "BEFORE_IMAGE_9 = ''  # @param {type:\"string\"}\n",
    "# @markdown ---\n",
    "AFTER_IMAGE_0 = ''  # @param {type:\"string\"}\n",
    "AFTER_IMAGE_1 = ''  # @param {type:\"string\"}\n",
    "AFTER_IMAGE_2 = ''  # @param {type:\"string\"}\n",
    "AFTER_IMAGE_3 = ''  # @param {type:\"string\"}\n",
    "AFTER_IMAGE_4 = ''  # @param {type:\"string\"}\n",
    "AFTER_IMAGE_5 = ''  # @param {type:\"string\"}\n",
    "AFTER_IMAGE_6 = ''  # @param {type:\"string\"}\n",
    "AFTER_IMAGE_7 = ''  # @param {type:\"string\"}\n",
    "AFTER_IMAGE_8 = ''  # @param {type:\"string\"}\n",
    "AFTER_IMAGE_9 = ''  # @param {type:\"string\"}\n",
    "\n",
    "# Constants\n",
    "SKAI_REPO = 'https://github.com/google-research/skai.git'\n",
    "OPEN_BUILDINGS_FEATURE_COLLECTION = 'GOOGLE/Research/open-buildings/v3/polygons'\n",
    "OSM_OVERPASS_URL = 'https://lz4.overpass-api.de/api/interpreter'\n",
    "TRAIN_TFRECORD_NAME = 'labeled_examples_train.tfrecord'\n",
    "TEST_TFRECORD_NAME = 'labeled_examples_test.tfrecord'\n",
    "\n",
    "# Derived variables\n",
    "SKAI_CODE_DIR = '/content/skai_src'\n",
    "AOI_PATH = os.path.join(OUTPUT_DIR, 'aoi.geojson')\n",
    "BUILDINGS_FILE_LOG = os.path.join(OUTPUT_DIR, 'buildings_file_log.txt')\n",
    "EXAMPLE_GENERATION_CONFIG_PATH = os.path.join(\n",
    "    OUTPUT_DIR, 'example_generation_config.json'\n",
    ")\n",
    "UNLABELED_TFRECORD_PATTERN = os.path.join(\n",
    "    OUTPUT_DIR, 'examples', 'unlabeled-large', 'unlabeled-*-of-*.tfrecord'\n",
    ")\n",
    "ZERO_SHOT_DIR = os.path.join(OUTPUT_DIR, 'zero_shot_model')\n",
    "ZERO_SHOT_SCORES = os.path.join(ZERO_SHOT_DIR, 'dataset_0_output.csv')\n",
    "LABELING_IMAGES_DIR = os.path.join(OUTPUT_DIR, 'labeling_images')\n",
    "LABELING_EXAMPLES_TFRECORD_PATTERN = os.path.join(\n",
    "    LABELING_IMAGES_DIR, '*', 'labeling_examples.tfrecord'\n",
    ")\n",
    "LABELS_CSV = os.path.join(OUTPUT_DIR, 'labels.csv')\n",
    "LABELED_EXAMPLES_ROOT = os.path.join(OUTPUT_DIR, 'labeled_examples')\n",
    "INFERENCE_CSV = os.path.join(OUTPUT_DIR, 'inference_scores.csv')\n",
    "\n",
    "\n",
    "def process_image_entries(entries: list[str]) -> list[str]:\n",
    "  image_ids = []\n",
    "  for entry in entries:\n",
    "    entry = entry.strip()\n",
    "    if entry:\n",
    "      image_ids.append(entry)\n",
    "  return image_ids\n",
    "\n",
    "\n",
    "BEFORE_IMAGES = process_image_entries([\n",
    "    BEFORE_IMAGE_0,\n",
    "    BEFORE_IMAGE_1,\n",
    "    BEFORE_IMAGE_2,\n",
    "    BEFORE_IMAGE_3,\n",
    "    BEFORE_IMAGE_4,\n",
    "    BEFORE_IMAGE_5,\n",
    "    BEFORE_IMAGE_6,\n",
    "    BEFORE_IMAGE_7,\n",
    "    BEFORE_IMAGE_8,\n",
    "    BEFORE_IMAGE_9,\n",
    "])\n",
    "\n",
    "AFTER_IMAGES = process_image_entries([\n",
    "    AFTER_IMAGE_0,\n",
    "    AFTER_IMAGE_1,\n",
    "    AFTER_IMAGE_2,\n",
    "    AFTER_IMAGE_3,\n",
    "    AFTER_IMAGE_4,\n",
    "    AFTER_IMAGE_5,\n",
    "    AFTER_IMAGE_6,\n",
    "    AFTER_IMAGE_7,\n",
    "    AFTER_IMAGE_8,\n",
    "    AFTER_IMAGE_9,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c271a",
   "metadata": {},
   "source": [
    "#Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b30da4",
   "metadata": {
    "cellView": "form",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# @title Install Libraries\n",
    "# @markdown This will take approximately 1 minute to run. After completing, you\n",
    "# @markdown may be prompted to restart the kernel. Select \"Restart\" and then\n",
    "# @markdown proceed to run the next cell.\n",
    "def install_requirements():\n",
    "  \"\"\"Installs necessary Python libraries.\"\"\"\n",
    "  !rm -rf {SKAI_CODE_DIR}\n",
    "  !git clone {SKAI_REPO} {SKAI_CODE_DIR}\n",
    "  !pip install {SKAI_CODE_DIR}/src/.\n",
    "\n",
    "  requirements = textwrap.dedent('''\n",
    "    apache_beam[gcp]==2.54.0\n",
    "    google-cloud-storage>=2.18.2  # https://github.com/apache/beam/issues/32169\n",
    "    ml-collections\n",
    "    openlocationcode\n",
    "    rasterio\n",
    "    rio-cogeo\n",
    "    rtree\n",
    "    tensorflow==2.14.0\n",
    "    tensorflow_addons\n",
    "    tensorflow_text\n",
    "    xmanager\n",
    "  ''')\n",
    "\n",
    "  requirements_file = '/content/requirements.txt'\n",
    "  with open(requirements_file, 'w') as f:\n",
    "    f.write(requirements)\n",
    "  !pip install -r {requirements_file}\n",
    "\n",
    "install_requirements()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccd086",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Authenticate with Google Cloud\n",
    "def authenticate():\n",
    "  auth.authenticate_user()\n",
    "  ee.Authenticate()\n",
    "  ee.Initialize(project=GCP_PROJECT)\n",
    "\n",
    "authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a73acf",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Imports and Function Defs\n",
    "%load_ext tensorboard\n",
    "\n",
    "import collections\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import shutil\n",
    "import subprocess\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import folium\n",
    "import folium.plugins\n",
    "import geopandas as gpd\n",
    "from google.colab import data_table\n",
    "from google.colab import files\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shapely.wkt\n",
    "from skai import earth_engine as skai_ee\n",
    "from skai import labeling\n",
    "from skai import open_street_map\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook\n",
    "\n",
    "data_table.enable_dataframe_formatter()\n",
    "\n",
    "\n",
    "def convert_wgs_to_utm(lon: float, lat: float):\n",
    "  \"\"\"Based on lat and lng, return best utm epsg-code.\"\"\"\n",
    "  utm_band = str((math.floor((lon + 180) / 6) % 60) + 1)\n",
    "  if len(utm_band) == 1:\n",
    "    utm_band = '0' + utm_band\n",
    "  if lat >= 0:\n",
    "    epsg_code = '326' + utm_band\n",
    "  else:\n",
    "    epsg_code = '327' + utm_band\n",
    "  return f'EPSG:{epsg_code}'\n",
    "\n",
    "\n",
    "def get_aoi_area_km2(aoi_path: str):\n",
    "  with tf.io.gfile.GFile(aoi_path) as f:\n",
    "    aoi = gpd.read_file(f)\n",
    "\n",
    "  centroid = aoi.geometry.unary_union.centroid\n",
    "  utm_crs = convert_wgs_to_utm(centroid.x, centroid.y)\n",
    "  utm_aoi = aoi.to_crs(utm_crs)\n",
    "  area_meters_squared = utm_aoi.geometry.unary_union.area\n",
    "  area_km_squared = area_meters_squared / 1000000\n",
    "  return area_km_squared\n",
    "\n",
    "\n",
    "def show_inference_stats(\n",
    "    aoi_path: str,\n",
    "    inference_csv_path: str,\n",
    "    threshold: float):\n",
    "  \"\"\"Prints out statistics on inference result.\"\"\"\n",
    "  with tf.io.gfile.GFile(inference_csv_path) as f:\n",
    "    df = pd.read_csv(f)\n",
    "  building_count = len(df)\n",
    "  if 'damage_score' in df.columns:\n",
    "    scores = df['damage_score']\n",
    "  elif 'score' in df.columns:\n",
    "    scores = df['score']\n",
    "  else:\n",
    "    raise ValueError(f'{inference_csv_path} does not contain a score column.')\n",
    "\n",
    "  damaged = df.loc[scores > threshold]\n",
    "  damaged_count = len(damaged)\n",
    "  damaged_pct = 100 * damaged_count / building_count\n",
    "  print('Area KM^2:', get_aoi_area_km2(aoi_path))\n",
    "  print('Buildings assessed:', building_count)\n",
    "  print('Damaged buildings:', damaged_count)\n",
    "  print(f'Percentage damaged: {damaged_pct:0.3g}%')\n",
    "\n",
    "\n",
    "def _open_file(path: str, mode: str):\n",
    "  f = tf.io.gfile.GFile(path, mode)\n",
    "  f.closed = False\n",
    "  return f\n",
    "\n",
    "\n",
    "def _file_exists(path: str) -> bool:\n",
    "  return bool(tf.io.gfile.glob(path))\n",
    "\n",
    "\n",
    "def _read_text_file(path: str) -> str:\n",
    "  with tf.io.gfile.GFile(path, 'r') as f:\n",
    "    return f.read()\n",
    "\n",
    "\n",
    "def _make_map(longitude: float, latitude: float, zoom: float):\n",
    "  \"\"\"Creates a Folium map with common base layers.\n",
    "\n",
    "  Args:\n",
    "    longitude: Longitude of initial view.\n",
    "    latitude: Latitude of initial view.\n",
    "    zoom: Zoom level of initial view.\n",
    "\n",
    "  Returns:\n",
    "    Folium map.\n",
    "  \"\"\"\n",
    "  base_maps = [\n",
    "      folium.TileLayer(\n",
    "          tiles='https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',\n",
    "          attr='Google',\n",
    "          name='Google Maps',\n",
    "          overlay=False,\n",
    "          control=True,\n",
    "      ),\n",
    "  ]\n",
    "\n",
    "  m = folium.Map(\n",
    "      location=(latitude, longitude),\n",
    "      max_zoom=24,\n",
    "      zoom_start=zoom,\n",
    "      tiles=None)\n",
    "  for base_map in base_maps:\n",
    "    base_map.add_to(m)\n",
    "  return m\n",
    "\n",
    "\n",
    "def show_assessment_heatmap(\n",
    "    aoi_path: str,\n",
    "    scores_path: str,\n",
    "    threshold: float,\n",
    "    is_zero_shot: bool):\n",
    "  \"\"\"Creates a Folium heatmap from inference scores.\"\"\"\n",
    "  with _open_file(scores_path, 'rb') as f:\n",
    "    df = pd.read_csv(f)\n",
    "  if is_zero_shot:\n",
    "    damaged = df.loc[~df['is_cloudy'] & (df['damage_score'] >= threshold)]\n",
    "  else:\n",
    "    damaged = df.loc[df['score'] >= threshold]\n",
    "  points = zip(damaged['latitude'].values, damaged['longitude'].values)\n",
    "  centroid_x = np.mean(damaged['longitude'].values)\n",
    "  centroid_y = np.mean(damaged['latitude'].values)\n",
    "  folium_map = _make_map(centroid_x, centroid_y, 12)\n",
    "  with _open_file(aoi_path, 'rb') as f:\n",
    "    aoi_gdf = gpd.read_file(f)\n",
    "  folium.GeoJson(\n",
    "      aoi_gdf.to_json(),\n",
    "      name='AOI',\n",
    "      style_function=lambda _: {'fillOpacity': 0},\n",
    "  ).add_to(folium_map)\n",
    "  heatmap = folium.plugins.HeatMap(points)\n",
    "  heatmap.add_to(folium_map)\n",
    "  display(folium_map)\n",
    "\n",
    "\n",
    "def make_download_button(path: str, file_name: str, caption: str):\n",
    "  \"\"\"Displays a button for downloading a file in the colab kernel.\"\"\"\n",
    "  def download(_):\n",
    "    temp_path = f'/tmp/{file_name}'\n",
    "    with _open_file(path, 'rb') as src:\n",
    "      with open(temp_path, 'wb') as dst:\n",
    "        shutil.copyfileobj(src, dst)\n",
    "    files.download(temp_path)\n",
    "\n",
    "  button = widgets.Button(\n",
    "      description=caption,\n",
    "  )\n",
    "  button.on_click(download)\n",
    "  display(button)\n",
    "\n",
    "\n",
    "def find_labeled_examples_dirs():\n",
    "  \"\"\"Returns directories containing labeled TFRecords.\"\"\"\n",
    "  dirs = tf.io.gfile.glob(os.path.join(LABELED_EXAMPLES_ROOT, '*'))\n",
    "  valid_dirs = []\n",
    "  for d in dirs:\n",
    "    train_path = os.path.join(d, TRAIN_TFRECORD_NAME)\n",
    "    test_path = os.path.join(d, TEST_TFRECORD_NAME)\n",
    "    valid = True\n",
    "    if not tf.io.gfile.exists(train_path):\n",
    "      print(\n",
    "          f'Warning: Train TFRecord does not exist in {d}, so not considering'\n",
    "          ' this a valid labeled dataset.'\n",
    "      )\n",
    "      valid = False\n",
    "    if not tf.io.gfile.exists(test_path):\n",
    "      print(\n",
    "          f'Warning: Test TFRecord does not exist in {d}, so not considering'\n",
    "          ' this a valid labeled dataset.'\n",
    "      )\n",
    "      valid = False\n",
    "    if not valid:\n",
    "      continue\n",
    "    valid_dirs.append(d)\n",
    "  return sorted(valid_dirs, reverse=True)\n",
    "\n",
    "\n",
    "def find_model_dirs():\n",
    "  # Find all checkpoints dirs first. We only want model dirs that have at least\n",
    "  # one checkpoint.\n",
    "  checkpoint_dirs = tf.io.gfile.glob(\n",
    "      os.path.join(LABELED_EXAMPLES_ROOT, '*/models/*/*/model/epoch-*-aucpr-*'))\n",
    "  model_dirs = set(os.path.dirname(os.path.dirname(p)) for p in checkpoint_dirs)\n",
    "  return sorted(model_dirs, reverse=True)\n",
    "\n",
    "\n",
    "def find_labeling_image_metadata_files(labeling_images_dir: str):\n",
    "  return tf.io.gfile.glob(os.path.join(\n",
    "      labeling_images_dir, '*', 'image_metadata.csv'))\n",
    "\n",
    "\n",
    "def yes_no_text(value: bool) -> str:\n",
    "  return '\\x1b[32mYES\\x1b[0m' if value else '\\x1b[31mNO\\x1b[0m'\n",
    "\n",
    "\n",
    "def visualize_images(images: list[tuple[np.ndarray, np.ndarray]]):\n",
    "  \"\"\"Displays before and after images side-by-side.\"\"\"\n",
    "  num_rows = len(images)\n",
    "  size_factor = 3\n",
    "  fig_size = (2 * size_factor, num_rows * size_factor)\n",
    "  fig, axes = plt.subplots(num_rows, 2, figsize=fig_size)\n",
    "  for row, (pre_image, post_image) in enumerate(images):\n",
    "    ax1 = axes[row, 0]\n",
    "    ax2 = axes[row, 1]\n",
    "    ax1.axis('off')\n",
    "    ax2.axis('off')\n",
    "    ax1.imshow(pre_image)\n",
    "    ax2.imshow(post_image)\n",
    "  plt.show(fig)\n",
    "\n",
    "\n",
    "def get_eeda_bearer_token(service_account: str) -> str:\n",
    "  return subprocess.check_output(\n",
    "      'gcloud auth print-access-token'\n",
    "      f' --impersonate-service-account=\"{service_account}\"',\n",
    "      shell=True,\n",
    "  ).decode()\n",
    "\n",
    "\n",
    "def get_timestamp() -> str:\n",
    "  return time.strftime('%Y%m%d_%H%M%S', time.localtime())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e19485",
   "metadata": {},
   "source": [
    "# Check Assessment Status\n",
    "\n",
    "Run the following cell to check which steps of the assessment have already\n",
    "been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce47df",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Check assessment status\n",
    "def check_assessment_status():\n",
    "  \"\"\"Shows which steps of the assessment have been completed.\"\"\"\n",
    "  print('AOI uploaded:', yes_no_text(_file_exists(AOI_PATH)))\n",
    "\n",
    "  if _file_exists(BUILDINGS_FILE_LOG):\n",
    "    buildings_file = _read_text_file(BUILDINGS_FILE_LOG).strip()\n",
    "    print('Building footprints generated:', yes_no_text(True))\n",
    "    print(f'  Building footprints file: {buildings_file}')\n",
    "  else:\n",
    "    print('Building footprints generated:', yes_no_text(False))\n",
    "\n",
    "  print(\n",
    "      'Example generation config file exists:',\n",
    "      yes_no_text(_file_exists(EXAMPLE_GENERATION_CONFIG_PATH)),\n",
    "  )\n",
    "  print(\n",
    "      'Unlabeled examples generated:',\n",
    "      yes_no_text(_file_exists(UNLABELED_TFRECORD_PATTERN)),\n",
    "  )\n",
    "  print(\n",
    "      'Zero-shot assessment generated:',\n",
    "      yes_no_text(_file_exists(ZERO_SHOT_SCORES)),\n",
    "  )\n",
    "  labeling_metadata_files = find_labeling_image_metadata_files(\n",
    "      LABELING_IMAGES_DIR\n",
    "  )\n",
    "  print(\n",
    "      'Labeling images generated:', yes_no_text(bool(labeling_metadata_files))\n",
    "  )\n",
    "  for p in labeling_metadata_files:\n",
    "    print(f'  {p}')\n",
    "  print('Label CSV uploaded:', yes_no_text(_file_exists(LABELS_CSV)))\n",
    "\n",
    "  labeled_examples_dirs = find_labeled_examples_dirs()\n",
    "  print(\n",
    "      'Labeled examples generated:', yes_no_text(bool(labeled_examples_dirs)))\n",
    "  if labeled_examples_dirs:\n",
    "    print('\\n'.join([f'  {d}' for d in labeled_examples_dirs]))\n",
    "  trained_model_dirs = find_model_dirs()\n",
    "  print('Fine-tuned model trained:', yes_no_text(bool(trained_model_dirs)))\n",
    "  if trained_model_dirs:\n",
    "    print('\\n'.join([f'  {d}' for d in trained_model_dirs]))\n",
    "\n",
    "  print(\n",
    "      'Fine-tuned inference generated:',\n",
    "      yes_no_text(_file_exists(INFERENCE_CSV)),\n",
    "  )\n",
    "\n",
    "check_assessment_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1b8072",
   "metadata": {},
   "source": [
    "# Example Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197a4696",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Upload AOI file\n",
    "def upload_aoi():\n",
    "  \"\"\"Shows button for user to upload AOI to the assessment directory.\"\"\"\n",
    "  if _file_exists(AOI_PATH):\n",
    "    print(f'AOI file {AOI_PATH} already exists.')\n",
    "    answer = input('Do you want to overwrite (y/n)? ')\n",
    "    if answer.lower() not in ['y', 'yes']:\n",
    "      print('AOI file not uploaded.')\n",
    "      return\n",
    "\n",
    "  uploaded = files.upload()\n",
    "\n",
    "  file_names = list(uploaded.keys())\n",
    "  if len(file_names) != 1:\n",
    "    print('You must choose exactly one GeoJSON file to upload.')\n",
    "    print('Upload NOT successful.')\n",
    "    return\n",
    "\n",
    "  if not file_names[0].endswith('.geojson'):\n",
    "    print('AOI file must be in GeoJSON format and have extension \".geojson\".')\n",
    "    print('Upload NOT successful.')\n",
    "    return\n",
    "\n",
    "  with _open_file(AOI_PATH, 'wb') as f:\n",
    "    f.write(uploaded[file_names[0]])\n",
    "\n",
    "upload_aoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ebc4e",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Get building footprints\n",
    "\n",
    "# pylint:disable=line-too-long\n",
    "BUILDINGS_METHOD = 'open_buildings'  # @param [\"open_buildings\",\"open_street_map\",\"run_model\",\"file\"]\n",
    "# pylint:enable=line-too-long\n",
    "# @markdown This is only needed if BUILDINGS_METHOD is set to \"file\":\n",
    "USER_BUILDINGS_FILE = ''  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "def download_open_buildings(aoi_path: str, output_dir: str) -> str:\n",
    "  path = os.path.join(output_dir, 'open_buildings.parquet')\n",
    "  with _open_file(aoi_path, 'r') as f:\n",
    "    gdf = gpd.read_file(f)\n",
    "  aoi = gdf.unary_union\n",
    "  skai_ee.get_open_buildings(\n",
    "      [aoi], OPEN_BUILDINGS_FEATURE_COLLECTION, 0.5, False, path)\n",
    "  return path\n",
    "\n",
    "\n",
    "def download_open_street_map(aoi_path: str, output_dir: str) -> str:\n",
    "  path = os.path.join(output_dir, 'open_street_map_buildings.parquet')\n",
    "  with _open_file(aoi_path, 'r') as f:\n",
    "    gdf = gpd.read_file(f)\n",
    "  aoi = gdf.unary_union\n",
    "  open_street_map.get_building_centroids_in_regions(\n",
    "      [aoi], OSM_OVERPASS_URL, path\n",
    "  )\n",
    "  return path\n",
    "\n",
    "\n",
    "def run_building_detection_model(\n",
    "    aoi_path: str,\n",
    "    output_dir: str):\n",
    "  \"\"\"Runs building detection model.\"\"\"\n",
    "  image_paths = ','.join(BEFORE_IMAGES)\n",
    "  child_dir = os.path.join(output_dir, 'buildings')\n",
    "  if any('EEDAI:' in image for image in BEFORE_IMAGES):\n",
    "    token = get_eeda_bearer_token(GCP_SERVICE_ACCOUNT)\n",
    "    eeda_bearer_env = f'export EEDA_BEARER=\"{token}\"'\n",
    "  else:\n",
    "    eeda_bearer_env = ''\n",
    "\n",
    "  script = textwrap.dedent(f'''\n",
    "    export PYTHONPATH={SKAI_CODE_DIR}/src:$PYTHONPATH\n",
    "    export GOOGLE_CLOUD_PROJECT={GCP_PROJECT}\n",
    "    {eeda_bearer_env}\n",
    "    cd {SKAI_CODE_DIR}/src\n",
    "    python detect_buildings_main.py \\\n",
    "      --cloud_project='{GCP_PROJECT}' \\\n",
    "      --cloud_region='{GCP_LOCATION}' \\\n",
    "      --worker_service_account='{GCP_SERVICE_ACCOUNT}' \\\n",
    "      --use_dataflow \\\n",
    "      --output_dir='{output_dir}' \\\n",
    "      --image_paths='{image_paths}' \\\n",
    "      --aoi_path='{aoi_path}' \\\n",
    "      --model_path='{BUILDING_SEGMENTATION_MODEL_PATH}'\n",
    "  ''')\n",
    "  script_path = '/content/run_building_detection.sh'\n",
    "  with open(script_path, 'w') as f:\n",
    "    f.write(script)\n",
    "  !bash {script_path}\n",
    "\n",
    "  buildings_file = os.path.join(child_dir, 'dedup_buildings.parquet')\n",
    "  return buildings_file\n",
    "\n",
    "\n",
    "def _display_building_footprints(buildings_gdf: gpd.GeoDataFrame):\n",
    "  \"\"\"Visualizes building footprints in a folium map.\"\"\"\n",
    "  centroid = buildings_gdf.centroid.unary_union.centroid\n",
    "\n",
    "  folium_map = _make_map(centroid.x, centroid.y, 13)\n",
    "  if len(buildings_gdf) > 100000:\n",
    "    print('Too many building footprints to display. Displaying random sample.')\n",
    "    buildings_gdf = buildings_gdf.sample_points(100000)\n",
    "  folium.GeoJson(\n",
    "      buildings_gdf.to_json(),\n",
    "      name='buildings',\n",
    "      marker=folium.CircleMarker(\n",
    "          radius=3, weight=0, fill_color='#FF0000', fill_opacity=1\n",
    "      ),\n",
    "  ).add_to(folium_map)\n",
    "  display(folium_map)\n",
    "\n",
    "\n",
    "def download_buildings(aoi_path: str, output_dir: str) -> None:\n",
    "  \"\"\"Downloads buildings to assessment directory.\"\"\"\n",
    "  if BUILDINGS_METHOD == 'open_buildings':\n",
    "    path = download_open_buildings(aoi_path, output_dir)\n",
    "  elif BUILDINGS_METHOD == 'open_street_map':\n",
    "    path = download_open_street_map(aoi_path, output_dir)\n",
    "  elif BUILDINGS_METHOD == 'run_model':\n",
    "    path = run_building_detection_model(aoi_path, output_dir)\n",
    "  elif BUILDINGS_METHOD == 'file':\n",
    "    path = USER_BUILDINGS_FILE\n",
    "  else:\n",
    "    raise ValueError(f'Unknown BUILDINGS_METHOD {BUILDINGS_METHOD}')\n",
    "\n",
    "  with _open_file(BUILDINGS_FILE_LOG, 'w') as f:\n",
    "    f.write(f'{path}\\n')\n",
    "\n",
    "  with _open_file(path, 'rb') as f:\n",
    "    if path.endswith('.csv'):\n",
    "      df = pd.read_csv(f)\n",
    "      df['geometry'] = df['wkt'].apply(shapely.wkt.loads)\n",
    "      gdf = gpd.GeoDataFrame(df.drop(columns=['wkt']), crs='EPSG:4326')\n",
    "    elif path.endswith('.parquet'):\n",
    "      gdf = gpd.read_parquet(f)\n",
    "    else:\n",
    "      gdf = gpd.read_file(f)\n",
    "  print(f'Found {len(gdf)} buildings.')\n",
    "  print(f'Saved buildings to {path}')\n",
    "  _display_building_footprints(gdf)\n",
    "\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "  warnings.simplefilter('ignore')\n",
    "  download_buildings(AOI_PATH, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384190bb",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Write Example Generation Config File\n",
    "def write_example_generation_config(path: str) -> None:\n",
    "  \"\"\"Writes example generation config file to assessment directory.\"\"\"\n",
    "  dataset_name = ASSESSMENT_NAME.lower().replace('_', '-')\n",
    "  with _open_file(BUILDINGS_FILE_LOG, 'r') as f:\n",
    "    buildings_file = f.read().strip()\n",
    "\n",
    "  config_dict = {\n",
    "      'dataset_name': dataset_name,\n",
    "      'aoi_path': AOI_PATH,\n",
    "      'output_dir': OUTPUT_DIR,\n",
    "      'buildings_method': 'file',\n",
    "      'buildings_file': buildings_file,\n",
    "      'resolution': 0.5,\n",
    "      'use_dataflow': True,\n",
    "      'cloud_project': GCP_PROJECT,\n",
    "      'cloud_region': GCP_LOCATION,\n",
    "      'worker_service_account': GCP_SERVICE_ACCOUNT,\n",
    "      'max_dataflow_workers': 100,\n",
    "      'output_shards': 100,\n",
    "      'output_metadata_file': True,\n",
    "      'before_image_patterns': BEFORE_IMAGES,\n",
    "      'after_image_patterns': AFTER_IMAGES,\n",
    "  }\n",
    "\n",
    "  valid_config = True\n",
    "  for key, value in config_dict.items():\n",
    "    if not value:\n",
    "      if key == 'buildings_file' and config_dict['buildings_method'] != 'file':\n",
    "        continue\n",
    "      print(f'Field {key} cannot be empty')\n",
    "      valid_config = False\n",
    "  if not valid_config:\n",
    "    return\n",
    "\n",
    "  config_string = json.dumps(config_dict, indent=2)\n",
    "  print(f'Example Generation configuration written to {path}:')\n",
    "  print()\n",
    "  print(config_string)\n",
    "  with tf.io.gfile.GFile(path, 'w') as f:\n",
    "    f.write(config_string)\n",
    "\n",
    "write_example_generation_config(EXAMPLE_GENERATION_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c376f",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Run Example Generation Job\n",
    "def run_example_generation(config_file_path: str):\n",
    "  \"\"\"Runs example generation pipeline.\"\"\"\n",
    "  if any('EEDAI:' in image for image in BEFORE_IMAGES):\n",
    "    token = get_eeda_bearer_token(GCP_SERVICE_ACCOUNT)\n",
    "    eeda_bearer_env = f'export EEDA_BEARER=\"{token}\"'\n",
    "  else:\n",
    "    eeda_bearer_env = ''\n",
    "\n",
    "  script = textwrap.dedent(f'''\n",
    "    cd {SKAI_CODE_DIR}/src\n",
    "    {eeda_bearer_env}\n",
    "    python generate_examples_main.py \\\n",
    "      --configuration_path={config_file_path} \\\n",
    "      --output_metadata_file\n",
    "  ''')\n",
    "\n",
    "  script_path = '/content/example_generation.sh'\n",
    "  with open(script_path, 'w') as f:\n",
    "    f.write(script)\n",
    "  !bash {script_path}\n",
    "\n",
    "run_example_generation(EXAMPLE_GENERATION_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb227715",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Visualize Generated Examples\n",
    "def visualize_generated_examples(pattern: str, num: int):\n",
    "  images = []\n",
    "  paths = tf.io.gfile.glob(pattern)\n",
    "  for record in tf.data.TFRecordDataset([paths[0]]).take(num):\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(record.numpy())\n",
    "    pre_image = plt.imread(io.BytesIO(\n",
    "        example.features.feature['pre_image_png_large'].bytes_list.value[0]))\n",
    "    post_image = plt.imread(io.BytesIO(\n",
    "        example.features.feature['post_image_png_large'].bytes_list.value[0]))\n",
    "    images.append((pre_image, post_image))\n",
    "  visualize_images(images)\n",
    "\n",
    "visualize_generated_examples(UNLABELED_TFRECORD_PATTERN, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df7b72",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Run Zero Shot Model\n",
    "def run_zero_shot_model():\n",
    "  \"\"\"Runs zero-shot model inference.\"\"\"\n",
    "  script = textwrap.dedent(f'''\n",
    "    export PYTHONPATH={SKAI_CODE_DIR}/src:$PYTHONPATH\n",
    "    export GOOGLE_CLOUD_PROJECT={GCP_PROJECT}\n",
    "    export GOOGLE_CLOUD_BUCKET_NAME={GCP_BUCKET}\n",
    "    cd {SKAI_CODE_DIR}/src\n",
    "\n",
    "    xmanager launch skai/model/xm_vlm_zero_shot_vertex.py -- \\\n",
    "      --example_patterns={UNLABELED_TFRECORD_PATTERN} \\\n",
    "      --output_dir={ZERO_SHOT_DIR}\n",
    "    ''')\n",
    "\n",
    "  print(\n",
    "      'Starting zero shot model inference. Scores will be written to'\n",
    "      f' {ZERO_SHOT_SCORES}'\n",
    "  )\n",
    "  script_path = '/content/zero_shot_model.sh'\n",
    "  with open(script_path, 'w') as f:\n",
    "    f.write(script)\n",
    "  !bash {script_path}\n",
    "\n",
    "run_zero_shot_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613f80f",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title View Zero Shot Assessment\n",
    "DAMAGE_SCORE_THRESHOLD = 0.5  # @param {type:\"number\"}\n",
    "\n",
    "make_download_button(\n",
    "    ZERO_SHOT_SCORES,\n",
    "    f'{ASSESSMENT_NAME}_zero_shot_assessment.csv',\n",
    "    'Download CSV')\n",
    "show_inference_stats(AOI_PATH, ZERO_SHOT_SCORES, DAMAGE_SCORE_THRESHOLD)\n",
    "show_assessment_heatmap(\n",
    "    AOI_PATH, ZERO_SHOT_SCORES, DAMAGE_SCORE_THRESHOLD, True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb8d0a9",
   "metadata": {},
   "source": [
    "# Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92a4eb",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Create Labeling Images\n",
    "MAX_LABELING_IMAGES = 1000  # @param {\"type\":\"integer\"}\n",
    "\n",
    "\n",
    "def visualize_labeling_images(images_dir: str, num: int):\n",
    "  \"\"\"Displays a small sample of labeling images.\"\"\"\n",
    "  pre_image_paths = sorted(\n",
    "      tf.io.gfile.glob(os.path.join(images_dir, '*_pre.png'))\n",
    "  )\n",
    "  post_image_paths = sorted(\n",
    "      tf.io.gfile.glob(os.path.join(images_dir, '*_post.png'))\n",
    "  )\n",
    "  assert len(pre_image_paths) == len(post_image_paths), (\n",
    "      f'Number of pre images ({len(pre_image_paths)}) does not match number of'\n",
    "      f' post images ({len(post_image_paths)}).'\n",
    "  )\n",
    "  images = []\n",
    "  for pre_image_path, post_image_path in list(\n",
    "      zip(pre_image_paths, post_image_paths)\n",
    "  )[:num]:\n",
    "    with _open_file(pre_image_path, 'rb') as f:\n",
    "      pre_image = plt.imread(f)\n",
    "    with _open_file(post_image_path, 'rb') as f:\n",
    "      post_image = plt.imread(f)\n",
    "    images.append((pre_image, post_image))\n",
    "  visualize_images(images)\n",
    "\n",
    "\n",
    "def create_labeling_images(\n",
    "    examples_pattern: str,\n",
    "    scores_file: str,\n",
    "    output_dir: str,\n",
    "    max_images: int,\n",
    "):\n",
    "  \"\"\"Creates labeling images.\"\"\"\n",
    "  if not tf.io.gfile.glob(examples_pattern):\n",
    "    print(\n",
    "        f'No files match \"{examples_pattern}\". Please run example generation'\n",
    "        ' first.'\n",
    "    )\n",
    "    return\n",
    "\n",
    "  existing_metadata_files = find_labeling_image_metadata_files(output_dir)\n",
    "  if existing_metadata_files:\n",
    "    print(\n",
    "        'The following labeling image metadata files have already been'\n",
    "        ' generated:'\n",
    "    )\n",
    "    print('\\n'.join(f'  {p}' for p in existing_metadata_files))\n",
    "    response = input(\n",
    "        'Do you want to generate a new set of labeling images (y/n)? '\n",
    "    )\n",
    "    if response.lower() not in ['y', 'yes']:\n",
    "      return\n",
    "\n",
    "  timestamp = get_timestamp()\n",
    "  images_dir = os.path.join(output_dir, timestamp)\n",
    "  metadata_csv = os.path.join(images_dir, 'image_metadata.csv')\n",
    "\n",
    "  num_images = labeling.create_labeling_images(\n",
    "      examples_pattern,\n",
    "      max_images,\n",
    "      set(),\n",
    "      set(),\n",
    "      images_dir,\n",
    "      True,\n",
    "      None,\n",
    "      4,\n",
    "      70.0,\n",
    "      {\n",
    "          (0, 0.25): 0.25,\n",
    "          (0.25, 0.5): 0.25,\n",
    "          (0.5, 0.75): 0.25,\n",
    "          (0.75, 1.0): 0.25,\n",
    "      },\n",
    "      scores_path=scores_file,\n",
    "      filter_by_column='is_cloudy',\n",
    "  )\n",
    "  print('Number of labeling images:', num_images)\n",
    "  print(\n",
    "      'Please create a new project in the SKAI labeling tool with the following'\n",
    "      ' metadata CSV:'\n",
    "  )\n",
    "  print(metadata_csv)\n",
    "  visualize_labeling_images(images_dir, 3)\n",
    "\n",
    "create_labeling_images(\n",
    "    UNLABELED_TFRECORD_PATTERN,\n",
    "    ZERO_SHOT_SCORES,\n",
    "    LABELING_IMAGES_DIR,\n",
    "    MAX_LABELING_IMAGES,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8d056c",
   "metadata": {},
   "source": [
    "When the labeling project is complete, download the CSV from the labeling tool\n",
    "and upload it to your assessment directory using the following cell.\n",
    "\n",
    "You may upload multiple CSV files at once, in case you wish to combine labels\n",
    "from multiple rounds of labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada766c8",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Upload Label CSV\n",
    "def upload_label_csvs(output_path: str):\n",
    "  \"\"\"Lets the user upload the labeling CSV file from their computer.\"\"\"\n",
    "  uploaded = files.upload()\n",
    "  dfs = []\n",
    "  for filename in uploaded.keys():\n",
    "    f = io.BytesIO(uploaded[filename])\n",
    "    df = pd.read_csv(f)\n",
    "    if 'example_id' not in df.columns:\n",
    "      print('\"example_id\" column not found in {filename}')\n",
    "      return\n",
    "    if 'string_label' not in df.columns:\n",
    "      print('\"string_label\" column not found in {filename}')\n",
    "      return\n",
    "    dfs.append(df)\n",
    "    print(f'Read {len(df)} rows from {filename}')\n",
    "\n",
    "  combined = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "  with tf.io.gfile.GFile(output_path, 'wb') as f:\n",
    "    f.closed = False\n",
    "    combined.to_csv(f, index=False)\n",
    "\n",
    "upload_label_csvs(LABELS_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d899c68",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Create Labeled Examples\n",
    "TEST_PERCENTAGE = 20  # @param {\"type\":\"integer\"}\n",
    "MINOR_IS_0 = True  # @param {\"type\":\"boolean\"}\n",
    "\n",
    "\n",
    "def create_labeled_examples(\n",
    "    examples_pattern: str,\n",
    "    labels_csv: str,\n",
    "    test_percent: int,\n",
    "    minor_is_0: bool,\n",
    "    labeled_examples_dir: str):\n",
    "  \"\"\"Creates labeled train and test TFRecords files.\"\"\"\n",
    "\n",
    "  assert test_percent < 100, 'Test percentage must be less than 100%.'\n",
    "  assert test_percent >= 1, 'Test percentage must be at least 1%.'\n",
    "  train_percent = 100 - test_percent\n",
    "  timestamp = get_timestamp()\n",
    "  output_dir = os.path.join(\n",
    "      labeled_examples_dir,\n",
    "      f'{timestamp}_{train_percent:02d}_{test_percent:02d}_minor{0 if minor_is_0 else 1}',\n",
    "  )\n",
    "  train_path = os.path.join(output_dir, TRAIN_TFRECORD_NAME)\n",
    "  test_path = os.path.join(output_dir, TEST_TFRECORD_NAME)\n",
    "  minor_damage_float_label = (0 if minor_is_0 else 1)\n",
    "  label_mapping = [\n",
    "      'bad_example=0',\n",
    "      'no_damage=0',\n",
    "      f'minor_damage={minor_damage_float_label}',\n",
    "      'major_damage=1',\n",
    "      'destroyed=1',\n",
    "  ]\n",
    "\n",
    "  labeling.create_labeled_examples(\n",
    "      label_file_paths=[labels_csv],\n",
    "      string_to_numeric_labels=label_mapping,\n",
    "      example_patterns=[examples_pattern],\n",
    "      test_fraction=test_percent / 100,\n",
    "      train_output_path=train_path,\n",
    "      test_output_path=test_path,\n",
    "      connecting_distance_meters=70.0,\n",
    "      use_multiprocessing=False,\n",
    "      multiprocessing_context=None,\n",
    "      max_processes=1,\n",
    "  )\n",
    "  print(f'Train TFRecord: {train_path}')\n",
    "  print(f'Test TFRecord: {test_path}')\n",
    "\n",
    "create_labeled_examples(\n",
    "    LABELING_EXAMPLES_TFRECORD_PATTERN,\n",
    "    LABELS_CSV,\n",
    "    TEST_PERCENTAGE,\n",
    "    MINOR_IS_0,\n",
    "    LABELED_EXAMPLES_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b256bd32",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Show Label Stats\n",
    "def _load_examples_into_df(\n",
    "    train_tfrecords: str,\n",
    "    test_tfrecords: str,\n",
    ") -> pd.DataFrame:\n",
    "  \"\"\"Loads examples from TFRecords into a DataFrame.\n",
    "  \"\"\"\n",
    "  feature_config = {\n",
    "      'example_id': tf.io.FixedLenFeature([], tf.string),\n",
    "      'coordinates': tf.io.FixedLenFeature([2], tf.float32),\n",
    "      'string_label': tf.io.FixedLenFeature([], tf.string, 'unlabeled'),\n",
    "      'label': tf.io.FixedLenFeature([], tf.float32),\n",
    "  }\n",
    "\n",
    "  def _parse_examples(record_bytes):\n",
    "    return tf.io.parse_single_example(record_bytes, feature_config)\n",
    "\n",
    "  columns = collections.defaultdict(list)\n",
    "  longitudes = []\n",
    "  latitudes = []\n",
    "  for path in [train_tfrecords, test_tfrecords]:\n",
    "    for features in tqdm.notebook.tqdm(\n",
    "        tf.data.TFRecordDataset([path])\n",
    "        .map(_parse_examples, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "        .as_numpy_iterator(),\n",
    "        desc=path,\n",
    "    ):\n",
    "      longitudes.append(features['coordinates'][0])\n",
    "      latitudes.append(features['coordinates'][1])\n",
    "      columns['example_id'].append(features['example_id'].decode())\n",
    "      columns['string_label'].append(features['string_label'].decode())\n",
    "      columns['label'].append(features['label'])\n",
    "      columns['source_path'].append(path)\n",
    "\n",
    "  return pd.DataFrame(columns)\n",
    "\n",
    "\n",
    "def _format_counts_table(df: pd.DataFrame):\n",
    "  for column in df.columns:\n",
    "    if column != 'All':\n",
    "      df[column] = [\n",
    "          f'{x}  ({x/t * 100:0.2f}%)' for x, t in zip(df[column], df['All'])\n",
    "      ]\n",
    "\n",
    "\n",
    "def show_label_stats(train_tfrecord: str, test_tfrecord: str):\n",
    "  \"\"\"Displays tables showing label count stats.\"\"\"\n",
    "  df = _load_examples_into_df(train_tfrecord, test_tfrecord)\n",
    "  counts = df.pivot_table(\n",
    "      index='source_path',\n",
    "      columns='string_label',\n",
    "      aggfunc='count',\n",
    "      values='example_id',\n",
    "      margins=True,\n",
    "      fill_value=0)\n",
    "  _format_counts_table(counts)\n",
    "\n",
    "  print('String Label Counts')\n",
    "  display(data_table.DataTable(counts))\n",
    "\n",
    "  float_counts = df.pivot_table(\n",
    "      index='source_path',\n",
    "      columns='label',\n",
    "      aggfunc='count',\n",
    "      values='example_id',\n",
    "      margins=True,\n",
    "      fill_value=0.0)\n",
    "  _format_counts_table(float_counts)\n",
    "  print('Float Label Counts')\n",
    "  display(data_table.DataTable(float_counts))\n",
    "\n",
    "\n",
    "def choose_dataset_show_label_stats():\n",
    "  \"\"\"Allows user to choose a labeled dataset and shows stats about it.\"\"\"\n",
    "  labeled_example_dirs = find_labeled_examples_dirs()\n",
    "  dir_select = widgets.Dropdown(\n",
    "      options=labeled_example_dirs,\n",
    "      description='Choose a labeled examples dir:',\n",
    "      layout={'width': 'initial'},\n",
    "  )\n",
    "  dir_select.style.description_width = 'initial'\n",
    "\n",
    "  show_stats_button = widgets.Button(description='Show Stats')\n",
    "  def show_stats(_):\n",
    "    show_stats_button.disabled = True\n",
    "    train_path = os.path.join(dir_select.value, TRAIN_TFRECORD_NAME)\n",
    "    test_path = os.path.join(dir_select.value, TEST_TFRECORD_NAME)\n",
    "    show_label_stats(train_path, test_path)\n",
    "\n",
    "  show_stats_button.on_click(show_stats)\n",
    "  display(dir_select)\n",
    "  display(show_stats_button)\n",
    "\n",
    "\n",
    "choose_dataset_show_label_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72f91a",
   "metadata": {},
   "source": [
    "# Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556419c",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Train model\n",
    "\n",
    "NUM_EPOCHS = 20  # @param {type:\"integer\"}\n",
    "\n",
    "\n",
    "def run_training(\n",
    "    experiment_name: str,\n",
    "    train_path: str,\n",
    "    test_path: str,\n",
    "    output_dir: str,\n",
    "    num_epochs: int):\n",
    "  \"\"\"Runs training job.\"\"\"\n",
    "  if not tf.io.gfile.exists(train_path):\n",
    "    raise ValueError(\n",
    "        f'Train TFRecord {train_path} does not exist. Did you run the \"Create'\n",
    "        ' Labeled Examples\" cell?'\n",
    "    )\n",
    "  if not tf.io.gfile.exists(test_path):\n",
    "    raise ValueError(\n",
    "        f'Test TFRecord {test_path} does not exist. Did you run the \"Create'\n",
    "        ' Labeled Examples\" cell?'\n",
    "    )\n",
    "\n",
    "  print(f'Train data: {train_path}')\n",
    "  print(f'Test data: {test_path}')\n",
    "  print(f'Model dir: {output_dir}')\n",
    "  job_args = {\n",
    "      'config': 'src/skai/model/configs/skai_two_tower_config.py',\n",
    "      'config.data.tfds_dataset_name': 'skai_dataset',\n",
    "      'config.data.adhoc_config_name': 'adhoc_dataset',\n",
    "      'config.data.labeled_train_pattern': train_path,\n",
    "      'config.data.validation_pattern': test_path,\n",
    "      'config.output_dir': output_dir,\n",
    "      'config.training.num_epochs': num_epochs,\n",
    "      'accelerator': 'V100',\n",
    "      'experiment_name': experiment_name,\n",
    "  }\n",
    "  job_arg_str = ' '.join(f'--{f}={v}' for f, v in job_args.items())\n",
    "  sh = textwrap.dedent(f'''\n",
    "    export GOOGLE_CLOUD_PROJECT={GCP_PROJECT}\n",
    "    export GOOGLE_CLOUD_BUCKET_NAME={GCP_BUCKET}\n",
    "    export PYTHONPATH={SKAI_CODE_DIR}/src\n",
    "    export LOCATION={GCP_LOCATION}\n",
    "\n",
    "    cd {SKAI_CODE_DIR}\n",
    "\n",
    "    xmanager launch src/skai/model/xm_launch_single_model_vertex.py -- \\\n",
    "    --xm_wrap_late_bindings \\\n",
    "    --xm_upgrade_db=True \\\n",
    "    --cloud_location=$LOCATION \\\n",
    "    --accelerator_count=1 {job_arg_str}''')\n",
    "\n",
    "  with open('script.sh', 'w') as file:\n",
    "    file.write(sh)\n",
    "\n",
    "  !bash script.sh\n",
    "\n",
    "\n",
    "def choose_dataset_run_training():\n",
    "  \"\"\"Allows user to choose a labeled dataset and trains a model using it.\"\"\"\n",
    "  labeled_example_dirs = find_labeled_examples_dirs()\n",
    "  dir_select = widgets.Dropdown(\n",
    "      options=labeled_example_dirs,\n",
    "      description='Choose a labeled examples dir:',\n",
    "      layout={'width': 'initial'},\n",
    "  )\n",
    "  dir_select.style.description_width = 'initial'\n",
    "\n",
    "  start_button = widgets.Button(description='Start Training')\n",
    "  def start_training(_):\n",
    "    start_button.disabled = True\n",
    "    train_path = os.path.join(dir_select.value, TRAIN_TFRECORD_NAME)\n",
    "    test_path = os.path.join(dir_select.value, TEST_TFRECORD_NAME)\n",
    "    model_dir = os.path.join(dir_select.value, 'models')\n",
    "    run_training(ASSESSMENT_NAME, train_path, test_path, model_dir, NUM_EPOCHS)\n",
    "\n",
    "  start_button.on_click(start_training)\n",
    "  display(dir_select)\n",
    "  display(start_button)\n",
    "\n",
    "choose_dataset_run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb8d601",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title View Tensorboard\n",
    "def start_tensorboard():\n",
    "  \"\"\"Shows Tensorboard visualization.\"\"\"\n",
    "  model_dirs = find_model_dirs()\n",
    "  tensorboard_dirs = [\n",
    "      tb\n",
    "      for d in model_dirs\n",
    "      if tf.io.gfile.isdir(tb := os.path.join(d, 'tensorboard'))\n",
    "  ]\n",
    "  if not tensorboard_dirs:\n",
    "    print(\n",
    "        'No Tensorboard directories found. Either you have not trained a model'\n",
    "        ' yet or a running job has not written any tensorboard log events yet.'\n",
    "    )\n",
    "    return\n",
    "\n",
    "  dir_selection_widget = widgets.Dropdown(\n",
    "      options=tensorboard_dirs,\n",
    "      description='Choose a tensorboard dir:',\n",
    "      layout={'width': 'initial'},\n",
    "  )\n",
    "  dir_selection_widget.style.description_width = 'initial'\n",
    "\n",
    "  start_button = widgets.Button(description='Start')\n",
    "  def run_tensorboard(_):\n",
    "    # pylint:disable=unused-variable\n",
    "    start_button.disabled = True\n",
    "    tensorboard_dir = dir_selection_widget.value\n",
    "    %tensorboard --load_fast=false --logdir $tensorboard_dir\n",
    "    # pylint:enable=unused-variable\n",
    "\n",
    "  start_button.on_click(run_tensorboard)\n",
    "\n",
    "  display(dir_selection_widget)\n",
    "  display(start_button)\n",
    "\n",
    "start_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7224a5e1",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Run inference\n",
    "def get_best_checkpoint(model_dir: str):\n",
    "  checkpoint_dirs = tf.io.gfile.glob(os.path.join(model_dir, 'epoch-*-aucpr-*'))\n",
    "  best_checkpoint = None\n",
    "  best_aucpr = 0\n",
    "  for checkpoint in checkpoint_dirs:\n",
    "    aucpr = float(checkpoint.split('-')[-1])\n",
    "    if aucpr > best_aucpr:\n",
    "      best_checkpoint = checkpoint\n",
    "      best_aucpr = aucpr\n",
    "  return best_checkpoint\n",
    "\n",
    "\n",
    "def run_inference(\n",
    "    examples_pattern: str,\n",
    "    model_dir: str,\n",
    "    output_dir: str,\n",
    "    output_path: str,\n",
    "    cloud_project: str,\n",
    "    cloud_region: str,\n",
    "    service_account: str) -> None:\n",
    "  \"\"\"Starts model inference job.\"\"\"\n",
    "  temp_dir = os.path.join(output_dir, 'inference_temp')\n",
    "  print(\n",
    "      f'Running inference with model checkpoint \"{model_dir}\" on examples'\n",
    "      f' matching \"{examples_pattern}\"'\n",
    "  )\n",
    "  print(f'Output will be written to {output_path}')\n",
    "\n",
    "  # accelerator_flags = ' '.join([\n",
    "  #     '--worker_machine_type=n1-highmem-8',\n",
    "  #     '--accelerator=nvidia-tesla-t4',\n",
    "  #     '--accelerator_count=1'])\n",
    "\n",
    "  # Currently, Colab only supports Python 3.10. However, the docker images we\n",
    "  # need for GPU acceleration are based on Tensorflow 2.14.0 images, which are\n",
    "  # based on Python 3.11. If we try to launch an inference job with GPU\n",
    "  # acceleration, Dataflow will complain about a Python version mismatch.\n",
    "  # Therefore, we can only use CPU inference until Colab upgrades to Python 3.11\n",
    "  # (which should be sometime within 2024).\n",
    "  accelerator_flags = ''\n",
    "\n",
    "  script = textwrap.dedent(f'''\n",
    "    cd {SKAI_CODE_DIR}/src\n",
    "    export PYTHONPATH={SKAI_CODE_DIR}/src:$PYTHONPATH\n",
    "    export GOOGLE_CLOUD_PROJECT={cloud_project}\n",
    "    python skai/model/inference.py \\\n",
    "      --examples_pattern='{examples_pattern}' \\\n",
    "      --image_model_dir='{model_dir}' \\\n",
    "      --output_path='{output_path}' \\\n",
    "      --use_dataflow \\\n",
    "      --cloud_project='{cloud_project}' \\\n",
    "      --cloud_region='{cloud_region}' \\\n",
    "      --dataflow_temp_dir='{temp_dir}' \\\n",
    "      --worker_service_account='{service_account}' \\\n",
    "      --threshold=0.5 \\\n",
    "      --high_precision_threshold=0.75 \\\n",
    "      --high_recall_threshold=0.4 \\\n",
    "      --max_dataflow_workers=4 {accelerator_flags}\n",
    "  ''')\n",
    "\n",
    "  script_path = '/content/inference_script.sh'\n",
    "  with open(script_path, 'w') as f:\n",
    "    f.write(script)\n",
    "  !bash {script_path}\n",
    "\n",
    "\n",
    "def do_inference():\n",
    "  \"\"\"Runs model inference.\"\"\"\n",
    "  model_dirs = find_model_dirs()\n",
    "  if not model_dirs:\n",
    "    print('No trained model directories found. Please train a model first.')\n",
    "    return\n",
    "\n",
    "  model_selection_widget = widgets.Dropdown(\n",
    "      options=model_dirs,\n",
    "      description='Choose a model:',\n",
    "      layout={'width': 'initial'},\n",
    "  )\n",
    "  model_selection_widget.style.description_width = 'initial'\n",
    "  start_button = widgets.Button(description='Start')\n",
    "\n",
    "  def start_clicked(_):\n",
    "    start_button.disabled = True\n",
    "    model_dir = os.path.join(model_selection_widget.value, 'model')\n",
    "    checkpoint = get_best_checkpoint(model_dir)\n",
    "    if not checkpoint:\n",
    "      print('Model directory does not contain a valid checkpoint directory.')\n",
    "      return\n",
    "    run_inference(\n",
    "        UNLABELED_TFRECORD_PATTERN,\n",
    "        checkpoint,\n",
    "        OUTPUT_DIR,\n",
    "        INFERENCE_CSV,\n",
    "        GCP_PROJECT,\n",
    "        GCP_LOCATION,\n",
    "        GCP_SERVICE_ACCOUNT,\n",
    "    )\n",
    "\n",
    "  start_button.on_click(start_clicked)\n",
    "\n",
    "  display(model_selection_widget)\n",
    "  display(start_button)\n",
    "\n",
    "\n",
    "do_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c28b8fd",
   "metadata": {
    "cellView": "form"
   },
   "outputs": [],
   "source": [
    "# @title Get assessment stats\n",
    "DAMAGE_SCORE_THRESHOLD = 0.5  # @param {type:\"number\"}\n",
    "\n",
    "make_download_button(\n",
    "    INFERENCE_CSV,\n",
    "    f'{ASSESSMENT_NAME}_assessment.csv',\n",
    "    'Download CSV')\n",
    "show_inference_stats(AOI_PATH, INFERENCE_CSV, DAMAGE_SCORE_THRESHOLD)\n",
    "show_assessment_heatmap(AOI_PATH, INFERENCE_CSV, DAMAGE_SCORE_THRESHOLD, False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "cellView,-all",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
