{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-research/skai/blob/skai-colab-0000003/src/colab/Run_SKAI_Colab_Pipeline_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZ4Nbz5x6Bw"
      },
      "source": [
        "#SKAI is the limit 🚀\n",
        "*Assessing Post-Disaster Damage 🏚️ from Satellite Imagery 🛰️ using Semi-Supervised Learning Techniques 📔*\n",
        "\n",
        "*Contributors: Joseph Xu, Jihyeon Lee, Tomer Shekel, Fiona Huang, Amine Baha* \n",
        "\n",
        "*Co-developped by Google Research AI and WFP Innovation Accelerator, January 2023*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intro 🏹"
      ],
      "metadata": {
        "id": "A1IfnanckHeo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAc_6ag50kyU"
      },
      "source": [
        "WFP partnered with Google Research to set up **SKAI**, a humanitarian response mapping solution powered by artificial intelligence — an approach that combines statistical methods, data and modern computing techniques to automate specific tasks. SKAI assesses damage to buildings by applying computer vision — computer algorithms that can interpret information extracted from visual materials such as, in this case, **satellite images of areas impacted by conflict, climate events, or other disasters**.\n",
        "\n",
        "![Skai Logo](https://storage.googleapis.com/skai-public/skai_logo.png)\n",
        "\n",
        "The type of machine learning used in SKAI, learns from a small number of labeled and a large number of unlabeled images of affected buildings. SKAI uses a ***semi-supervised learning technique*** that reduces the required number of labeled examples by an order of magnitude. As such, SKAI models typically *only need a couple hundred labeled examples* to achieve high accuracy, significantly improving the speed at which accurate results can be obtained.\n",
        "\n",
        "Google Research presented this novel application of semi-supervised learning (SSL) to train models for damage assessment with a minimal amount of labeled data and large amount of unlabeled data in [June 2020](https://ai.googleblog.com/2020/06/machine-learning-based-damage.html). Using the state-of-the-art methods including [MixMatch](https://arxiv.org/abs/1905.02249) and [FixMatch](https://arxiv.org/abs/2001.07685), they compare the performance with supervised baseline for the 2010 Haiti earthquake, 2017 Santa Rosa wildfire, and 2016 armed conflict in Syria.\n",
        "\n",
        "![SSL Approach](https://storage.googleapis.com/skai-public/ssl_diagram.png)\n",
        "\n",
        "The [paper](https://arxiv.org/abs/2011.14004) published by *Jihyeon Lee, Joseph Z. Xu, Kihyuk Sohn, Wenhan Lu, David Berthelot, Izzeddin Gur, Pranav Khaitan, Ke-Wei, Huang, Kyriacos Koupparis, Bernhard Kowatsch* shows how models trained with SSL methods can reach fully supervised performance despite using only a fraction of labeled data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nihwE_UZFilS"
      },
      "source": [
        "## Notebook Setup 📓\n",
        "\n",
        "**Before running this Colab notebook, we recommend to initialize your kernel using [Initialize SKAI Colab Kernel Notebook](https://github.com/google-research/skai/blob/main/src/colab/Initialize_SKAI_Colab_Kernel.ipynb).**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "#@title Please run this cell first!\n",
        "\n",
        "#@markdown Specify the parameters to set up your Colab notebook. They should be the same that the ones used during the initialization of the Colab kernel\n",
        "#############################################\n",
        "### CODE SETTING - ENVIRONMENT ACTIVATION ###\n",
        "#############################################\n",
        "#@markdown ---\n",
        "#@markdown Please enter the path to the **git repository** and **colab workspace directory** to use:\n",
        "\n",
        "#@markdown ---\n",
        "SKAI_CODE_DIR = \"/content/skai_src\"  #@param {type:\"string\"}\n",
        "SKAI_VENV_DIR = \"/content/skai_env\"  #@param {type:\"string\"}\n",
        "SKAI_REPO = \"https://github.com/google-research/skai.git\"  #@param {type:\"string\"}\n",
        "SKAI_BRANCH = \"main\"  #@param {type:\"string\"}\n",
        "SKAI_COMMIT = \"\" #@param {type:\"string\"}\n",
        "\n",
        "root_filesys=os.path.dirname(SKAI_CODE_DIR)\n",
        "\n",
        "pathsys_venv=SKAI_VENV_DIR\n",
        "pathsys_actenv=os.path.join(pathsys_venv, 'bin/activate')\n",
        "\n",
        "pathsys_skai=SKAI_CODE_DIR\n",
        "%shell rm -rf {SKAI_CODE_DIR}\n",
        "%shell git clone -b {SKAI_BRANCH} {SKAI_REPO} {SKAI_CODE_DIR}\n",
        "if SKAI_COMMIT!='':\n",
        "  %shell cd {SKAI_CODE_DIR} ; git checkout {SKAI_COMMIT}\n",
        "\n",
        "%cd {SKAI_CODE_DIR}/src/colab\n",
        "import colab_utils\n",
        "from colab_utils import *\n",
        "\n",
        "def launch_pexpect_process(script, arguments,dir_args, use_pexpect, sleep=None):\n",
        "  if not isinstance(script, list):\n",
        "    script=[script]\n",
        "    arguments=[arguments]\n",
        "  \n",
        "  if sleep==None and len(script)>1:\n",
        "    sleep=[0] * (len(script)-1)\n",
        "  elif len(script)==1:\n",
        "    sleep==None\n",
        "\n",
        "  flags_str = [' '.join(f\"--{f}='{v}'\" for f, v in argument.items()) for argument in arguments] \n",
        "  commands = '; '.join([\n",
        "      f'set -e',\n",
        "      f'source {dir_args[\"python_env\"]}',\n",
        "      f'export GOOGLE_APPLICATION_CREDENTIALS={dir_args[\"path_cred\"]}',\n",
        "      f'python {dir_args[\"path_skai\"]}/src/{script[0]} {flags_str[0]}'])\n",
        "  \n",
        "  if sleep is not None:\n",
        "    commands_bis=' '.join([\n",
        "      '; '.join([f'& sleep {sleep[i-1]} ',f'python {dir_args[\"path_skai\"]}/src/{script[i]} {flags_str[i]}']) for i in range(1,len(script))])\n",
        "    \n",
        "    commands=' '.join([commands, commands_bis])\n",
        "\n",
        "  \n",
        "  sh_command = f'bash -c \"{commands}\" | tee /tmp/output.txt'\n",
        "  print(sh_command,'\\n')\n",
        "\n",
        "  if use_pexpect:\n",
        "    return pexpect.spawn(sh_command)\n",
        "  else:\n",
        "    with open('/tmp/shell_command.sh', 'w') as f:\n",
        "      f.write(commands)\n",
        "    !bash \"/tmp/shell_command.sh\" | tee /tmp/output.txt\n",
        "\n",
        "def load_start_tensorboard(path_log):\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir gs://{path_log}\n",
        "\n",
        "colab_utils.launch_pexpect_process=launch_pexpect_process\n",
        "colab_utils.load_start_tensorboard=load_start_tensorboard\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nKdcp4cscn3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input project parameters\n",
        "\n",
        "#@markdown Specify the variables to set your damage assessment project and press play:\n",
        "#############################################\n",
        "### INITIAL SETTING - PROJECT DESCRIPTION ###\n",
        "#############################################\n",
        "#@markdown ---\n",
        "#@markdown Please enter here the parameters for your **project desciption**\n",
        "\n",
        "#@markdown ---\n",
        "Disaster = 'Cyclone' #@param [\"Cyclone\", \"Earthquake\", \"Tsunami\", \"Flood\", \"Eruption\", \"Tornado\", \"Wind\", \"Wildfire\", \"Landslide\", \"Conflict\"]\n",
        "Year =  None #@param {type:\"integer\"}\n",
        "Month =  None #@param {type:\"integer\"}\n",
        "Name = '' #@param {type:\"string\"}\n",
        "Country = '' #@param {type:\"string\"}\n",
        "Organisation = '' #@param {type:\"string\"}\n",
        "Author = '' #@param {type:\"string\"}\n",
        "Run = '' #@param {type:\"string\"}\n",
        "\n",
        "Project_description= f\"{Organisation}-{Disaster}-{Name}-{Country}-{Year}{Month:02d}_{Run}\".lower()\n",
        "GD_DIRECTORY = f\"{Project_description}\".lower()\n",
        "\n",
        "####################################################\n",
        "### CLOUD SETTING - PROJECT/BUCKET CONFIGURATION ###\n",
        "####################################################\n",
        "#@markdown ---\n",
        "#@markdown Please enter the parameters of **google cloud platform account** to use:\n",
        "\n",
        "#@markdown ---\n",
        "GCP_PROJECT = \"\" #@param {type:\"string\"}\n",
        "GCP_LOCATION = \"\" #@param {type:\"string\"}\n",
        "GCP_SERVICE_ACCOUNT=\"\"#@param {type:\"string\"}\n",
        "\n",
        "GCP_LOCATION_LABELING=GCP_LOCATION\n",
        "if \"europe-\" in GCP_LOCATION :\n",
        "  GCP_LOCATION_LABELING= \"europe-west4\"\n",
        "  if GCP_LOCATION!= \"europe-west1\" :\n",
        "    GCP_LOCATION= \"europe-west1\"\n",
        "    print(f\"\\nLocation region has been changed to {GCP_LOCATION} (Vertex AI features availability) \")\n",
        "if \"us-\" in GCP_LOCATION :\n",
        "  GCP_LOCATION_LABELING= \"us-central1\"\n",
        "  if GCP_LOCATION!= \"us-central1\" :\n",
        "    GCP_LOCATION= \"us-central1\"\n",
        "    print(f\"\\nLocation region has been changed to {GCP_LOCATION} (Vertex AI features availability) \")\n",
        "\n",
        "GCP_PROJECT_ID=get_project_id(GCP_PROJECT)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Please enter the parameters of **google cloud bucket** to use:\n",
        "\n",
        "Tool=\"Colab\"\n",
        "\n",
        "#@markdown ---\n",
        "BCKT_VERSION = \"\" #@param {type:\"string\"}\n",
        "GCP_BUCKET = f\"{GCP_PROJECT}{Tool}-Bucket-{BCKT_VERSION}_{Author}\".lower() \n",
        "\n",
        "#@markdown A bucket will be created in your project, named as *\\<GCP_PROJECT>*colab-bucket-*\\<BCKT_VERSION>*_*\\<Author>*\n",
        "\n",
        "if not bucket_exists(GCP_PROJECT, GCP_BUCKET):\n",
        "  create_bucket(GCP_PROJECT, GCP_LOCATION, GCP_BUCKET)\n",
        "\n",
        "print(f\"\\nYour project bucket in Google Cloud: {GCP_BUCKET} \\nhttps://console.cloud.google.com/storage/browser/{GCP_BUCKET}\")\n",
        "print(f\"\\nYour project folder: {Project_description}\")\n",
        "\n",
        "pathgcp_outputdir=os.path.join(GCP_BUCKET,GD_DIRECTORY)\n",
        "\n",
        "service_account = GCP_SERVICE_ACCOUNT\n",
        "pathsys_credentials = '/root/service-account-private-key.json'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = pathsys_credentials\n",
        "\n",
        "# Prepare credentials for map visualization.\n",
        "credentials = ee.ServiceAccountCredentials(service_account, pathsys_credentials)\n",
        "#Register the service account : https://signup.earthengine.google.com/#!/service_accounts\n",
        "ee.Initialize(credentials)\n",
        "\n",
        "pathsys_args={\n",
        "    'python_env':pathsys_actenv,\n",
        "    'path_skai':pathsys_skai,\n",
        "    'path_cred':pathsys_credentials\n",
        "}\n",
        "\n",
        "#########################################\n",
        "### IMAGE SETTING - FILE & DIRECTORY ###\n",
        "#########################################\n",
        "#@markdown ---\n",
        "#@markdown Please enter the path to the files of **pre and post disaster satellite images** and **area of interest**:\n",
        "\n",
        "#@markdown ---\n",
        "#IMAGERY_INPUT = \"mosaic_images\" #@param [\"single_image\", \"mosaic_images\"]\n",
        "FILE_IMAGE_BEFORE = 'gs://bucket_path/*_Pre.tif' #@param {type:\"string\"}\n",
        "FILE_IMAGE_AFTER = 'gs://bucket_path/*_Post.tif' #@param {type:\"string\"}\n",
        "#@markdown Provide prefix of image filenames (replacing * in previous input), separated by commas. If consider all files, leave blank.\n",
        "IMAGE_PREFIX_BEFORE = '' #@param {type:\"string\"}\n",
        "IMAGE_PREFIX_AFTER = '' #@param {type:\"string\"}\n",
        "FILE_IMAGE_AOI = 'gs://bucket_path/*.geojson' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Choose where to get **building footprints** from:\n",
        "BUILDING_DETECTION_METHOD = \"open_buildings\" #@param [\"open_buildings\",\"open_street_map\",\"file\"]\n",
        "#@markdown If you chose \"file\", please enter path to CSV file here:\n",
        "BUILDINGS_CSV = '' #@param {type:\"string\"}\n",
        "\n",
        "pathgcp_imagesource=os.path.dirname(FILE_IMAGE_BEFORE).replace('gs://','')\n",
        "pathgcp_images=os.path.join(pathgcp_outputdir,'images')\n",
        "\n",
        "if IMAGE_PREFIX_BEFORE=='':\n",
        "  file_path_split=FILE_IMAGE_BEFORE.split('/')\n",
        "  name_pattern='/'.join(file_path_split[3:])\n",
        "  url='https://storage.googleapis.com/storage/v1/b/{}/o'.format(file_path_split[2])\n",
        "  data = make_gcp_http_request(url)\n",
        "  IMAGE_PREFIX_BEFORE=','.join([re.search(name_pattern.replace('*','(.*)'),d['name']).group(1) for d in data['items'] if re.search(name_pattern.replace('*','(.*)'),d['name'])])\n",
        "  \n",
        "pathgcp_imagebefore=[FILE_IMAGE_BEFORE.replace('*',prefix.strip()) for prefix in IMAGE_PREFIX_BEFORE.split(',')]\n",
        "pathgcp_imagebefore= ','.join(pathgcp_imagebefore)\n",
        "\n",
        "if IMAGE_PREFIX_AFTER=='':\n",
        "  file_path_split=FILE_IMAGE_AFTER.split('/')\n",
        "  name_pattern='/'.join(file_path_split[3:])\n",
        "  url='https://storage.googleapis.com/storage/v1/b/{}/o'.format(file_path_split[2])\n",
        "  data = make_gcp_http_request(url)\n",
        "  IMAGE_PREFIX_AFTER=','.join([re.search(name_pattern.replace('*','(.*)'),d['name']).group(1) for d in data['items'] if re.search(name_pattern.replace('*','(.*)'),d['name'])])\n",
        "  \n",
        "pathgcp_imageafter=[FILE_IMAGE_AFTER.replace('*',prefix.strip()) for prefix in IMAGE_PREFIX_AFTER.split(',')]\n",
        "pathgcp_imageafter= ','.join(pathgcp_imageafter)\n",
        "\n",
        "pathgcp_aoi=FILE_IMAGE_AOI\n",
        "\n",
        "#########################################\n",
        "### EXAMPLE SETTING - CLOUD DIRECTORY ###\n",
        "#########################################\n",
        "pathgcp_examples=os.path.join(pathgcp_outputdir,'examples')\n",
        "pathgcp_pattern=os.path.join(pathgcp_examples,'unlabeled-large/*.tfrecord')\n",
        "pathgcp_importfolder=os.path.join(pathgcp_examples,'labeling_images')\n",
        "pathgcp_importfile=os.path.join(pathgcp_importfolder,'import_file.csv')\n",
        "\n",
        "###########################################\n",
        "### LABELING SETTING - EMAIL PARAMETERS ###\n",
        "###########################################\n",
        "#@markdown ---\n",
        "#@markdown Provide **email addresses** for all individuals that will help with labeling images, separated by commas.\n",
        "#@markdown Emails of the labelers need to be linked to a google account.\n",
        "\n",
        "#@markdown ---\n",
        "EMAIL_MANAGER = 'manager@gmail.com' #@param {type:\"string\"}\n",
        "EMAIL_ANNOTATORS = 'annotator1@gmail.com,annotator2@gmail.com' #@param {type:\"string\"}\n",
        "\n",
        "if EMAIL_MANAGER.strip() in EMAIL_ANNOTATORS:\n",
        "  EMAIL_ANNOTATORS.replace(EMAIL_MANAGER.strip(), '')\n",
        "GCP_LABELER_EMAIL = [EMAIL_MANAGER.strip()] + [email.strip() for email in EMAIL_ANNOTATORS.split(',')]\n",
        "GCP_LABELER_EMAIL = ','.join(GCP_LABELER_EMAIL)\n",
        "\n",
        "################################################\n",
        "### DATASET SETTING - FILE & CLOUD DIRECTORY ###\n",
        "################################################\n",
        "pathgcp_temp=os.path.join(pathgcp_outputdir,'temp')\n",
        "pathgcp_unlabeled=os.path.join(pathgcp_examples,'unlabeled/*.tfrecord')\n",
        "\n",
        "pathgcp_trainset=os.path.join(pathgcp_examples,'labeled_train_examples.tfrecord')\n",
        "pathgcp_testset=os.path.join(pathgcp_examples,'labeled_test_examples.tfrecord')\n",
        "\n",
        "#######################################\n",
        "### MODEL SETTING - FILE & DIRECTORY ##\n",
        "#######################################\n",
        "pathsys_runjobs=os.path.join(root_filesys,'run_jobs')\n",
        "if not os.path.exists(pathsys_runjobs):\n",
        "  os.mkdir(pathsys_runjobs)\n",
        "\n",
        "pathgcp_models=os.path.join(pathgcp_outputdir,'models')\n"
      ],
      "metadata": {
        "id": "dDtCZ5QvYBom",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esh2w1R5AAJy"
      },
      "source": [
        "## Data labeling 👷\n",
        "\n",
        "Create examples of buildings images before and after the disaster and classify them as either undamaged, possibly damaged, damaged/destroyed, or bad example (e.g., cloud cover etc.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize before and after images\n",
        "\n",
        "display(Javascript(\"google.colab.output.resizeIframeToContent()\"))\n",
        "create_folium_map_with_images(pathgcp_imagebefore, pathgcp_imageafter)"
      ],
      "metadata": {
        "id": "2rqwIPUfjq4H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Examples\n",
        "#@markdown First, generate the building images. This task should take about 30-45 minutes.\n",
        "\n",
        "## COMMAND RUN\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "GCP_DATASET_NAME = f\"{Author}_example_{timestamp}_{Project_description}\".replace(\"_\",\"-\")\n",
        "\n",
        "generate_examples_args = {\n",
        "    'cloud_project': GCP_PROJECT,\n",
        "    'cloud_region': GCP_LOCATION,\n",
        "    'dataset_name' : GCP_DATASET_NAME,\n",
        "    'before_image_patterns': pathgcp_imagebefore,\n",
        "    'after_image_patterns': pathgcp_imageafter,\n",
        "    'aoi_path': pathgcp_aoi,\n",
        "    'output_dir': f'gs://{pathgcp_outputdir}',\n",
        "    'buildings_method': BUILDING_DETECTION_METHOD,\n",
        "    'buildings_file': BUILDINGS_CSV,\n",
        "    'worker_service_account': service_account,\n",
        "    'earth_engine_service_account' : service_account,\n",
        "    'earth_engine_private_key' : pathsys_credentials,\n",
        "    'use_dataflow': 'true',\n",
        "}\n",
        "\n",
        "run_example_generation(generate_examples_args,pathsys_args,pretty_output=True)\n",
        "print(f\"\\nGenerated examples are saved in the folder :\\ngs://{pathgcp_outputdir}/examples\\n\")"
      ],
      "metadata": {
        "id": "J5qUmoZyed3j",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create Labeling Task\n",
        "\n",
        "#@markdown Second, create the labeling tasks for the labelers. This task should take about 15-30 minutes. \n",
        "\n",
        "#@markdown At the end of this step you and each labelers will receive an email with the instruction on how to perform the labeling task.\n",
        "\n",
        "#@markdown Enter the maximum number of images to label (by default, 1000) :\n",
        "MAX_IMAGES = 1000 #@param {type:\"integer\"}\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "GCP_DATASET_NAME = f\"{Author}_label_{timestamp}_{Project_description}\"\n",
        "if MAX_IMAGES==0 or MAX_IMAGES is None:\n",
        "  MAX_IMAGES=1000\n",
        "\n",
        "create_labeling_task_args = {\n",
        "    'cloud_project':GCP_PROJECT,\n",
        "    'cloud_location':GCP_LOCATION_LABELING,\n",
        "    'dataset_name': GCP_DATASET_NAME,\n",
        "    'examples_pattern': f'gs://{pathgcp_pattern}',\n",
        "    'images_dir':  f'gs://{pathgcp_importfolder}',\n",
        "    'cloud_labeler_emails': GCP_LABELER_EMAIL,\n",
        "    'max_images':MAX_IMAGES\n",
        "    }\n",
        "\n",
        "GCP_DATASET_ID ,GCP_DATASET_NAME,GCP_LABELING_JOB,GCP_LABELING_INSTRUCTION = run_labeling_task_creation(create_labeling_task_args,pathsys_args)"
      ],
      "metadata": {
        "id": "X4IvDFtsD-cV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Monitor Labeling Task\n",
        "\n",
        "#@markdown As a manager of the task, you can track the labeling progress by running this script below and see how many labels were created or view the detailed monitoring page. \n",
        "\n",
        "#@markdown For good quality we recommend having about 200-300 building labels from the damaged/destroyed and undamaged categories.\n",
        "\n",
        "#@markdown Enter a **labeling job** selection option. If you don't chose \"runtime_saved\", please enter the specific id of the job you would like to monitor.\n",
        "LABELING_JOB = \"runtime_saved\" #@param [\"runtime_saved\",\"id\"]\n",
        "JOB_ID = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if LABELING_JOB==\"id\":\n",
        "  GCP_LABELING_JOB=int(JOB_ID)\n",
        "elif LABELING_JOB==\"runtime_saved\":\n",
        "  if 'GCP_LABELING_JOB' not in locals():\n",
        "    raise Exception('''\n",
        "    Sorry, no Data Labeling job id is saved in your local runtine.\n",
        "    Please change selection option and specify id of your data labeling job.''')\n",
        "\n",
        "labeling_job = LabelingJob(f'{GCP_LOCATION_LABELING}-aiplatform.googleapis.com', \n",
        "                           GCP_PROJECT, GCP_LOCATION_LABELING, GCP_LABELING_JOB)\n",
        "print(f'\\nJob completion percentage: {labeling_job.get_completion_percentage()}% (Data Labeling job ID {GCP_LABELING_JOB})')"
      ],
      "metadata": {
        "id": "qSwaYjKLDry9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulMjwGaex8LK"
      },
      "source": [
        "## Training and evaluation datasets 🧩\n",
        "\n",
        "Assign the labeled images to training and evaluation datasets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create training and evaluation datasets\n",
        "\n",
        "#@markdown Enter a **labeling dataset** selection option. If you don't chose \"runtime_saved\", please enter the specific id of the dataset you would like to create your datasets.\n",
        "LABELING_DATASET = \"runtime_saved\" #@param [\"runtime_saved\",\"id\"]\n",
        "DATASET_ID = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if LABELING_DATASET==\"id\":\n",
        "  GCP_DATASET_ID=DATASET_ID\n",
        "elif LABELING_DATASET==\"runtime_saved\":\n",
        "  if 'GCP_DATASET_ID' not in locals():\n",
        "    raise Exception('''\n",
        "    Sorry, no Labeling dataset id is saved in your local runtine.\n",
        "    Please change selection option and specify id of your labeling dataset.''')\n",
        "\n",
        "create_labeled_dataset_args = {\n",
        "    'cloud_project':GCP_PROJECT,\n",
        "    'cloud_location':GCP_LOCATION_LABELING,\n",
        "    'cloud_dataset_id': GCP_DATASET_ID,\n",
        "    \"cloud_temp_dir\": f'gs://{pathgcp_temp}',\n",
        "    \"examples_pattern\": f'gs://{pathgcp_unlabeled}',\n",
        "    \"train_output_path\": f'gs://{pathgcp_trainset}',\n",
        "    \"test_output_path\": f'gs://{pathgcp_testset}'}\n",
        "\n",
        "create_labeled_dataset(create_labeled_dataset_args,pathsys_args)"
      ],
      "metadata": {
        "id": "9vSAGvIiTMhq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspect training and evaluation datasets (optional)"
      ],
      "metadata": {
        "id": "6ehjrJ1keXeJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K10K2imWSEcE",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Inspect the training dataset (optional)\n",
        "\n",
        "## COMMAND RUN\n",
        "COUNT_TRAIN_LABELED=visualize_labeled_examples(os.path.join(\"gs://\",pathgcp_trainset),max_examples=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfUy0Ympl4ko",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Inspect the evaluation dataset (optional)\n",
        "\n",
        "COUNT_TEST_LABELED=visualize_labeled_examples(os.path.join(\"gs://\",pathgcp_testset),max_examples=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0pTjiIeB-w"
      },
      "source": [
        "## Model training, performance evaluation 🤖\n",
        "\n",
        "Train the machine learning model and test it using the evaluation dataset (leveraging the examples you previously labeled).\n",
        "\n",
        "The script runs in the background and may take up to 6 hours. You will be able to see the progress on this page and we will also send you an email when this step is done."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train and evaluate model\n",
        "\n",
        "display(Javascript(\"google.colab.output.resizeIframeToContent()\"))\n",
        "\n",
        "#@markdown View Results in Tensorboard:\n",
        "LOAD_TENSORBOARD = 'Yes' #@param [\"Yes\",\"No\"]\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "GCP_EXPERIMENT_NAME=f\"{Author}_experiment_{timestamp}_{Project_description}_default\"\n",
        "GCP_TRAINJOB_NAME=f\"{Author}_train_{timestamp}_{Project_description}_default\"\n",
        "GCP_EVALJOB_NAME=f\"{Author}_eval_{timestamp}_{Project_description}_default\"\n",
        "\n",
        "pathgcp_exper=os.path.join(pathgcp_models, GCP_EXPERIMENT_NAME)\n",
        "\n",
        "generate_script_train_args={   \n",
        "    'project':GCP_PROJECT,\n",
        "    'location':GCP_LOCATION,\n",
        "    'job_type':'train',\n",
        "    'display_name':GCP_TRAINJOB_NAME,\n",
        "    'dataset_name':GCP_EXPERIMENT_NAME,\n",
        "    'train_worker_machine_type':'n1-highmem-16',\n",
        "    'train_docker_image_uri_path':'gcr.io/disaster-assessment/ssl-train-uri',\n",
        "    'service_account':service_account,\n",
        "    'train_dir':f'gs://{pathgcp_exper}',\n",
        "    'train_unlabel_examples':f'gs://{pathgcp_unlabeled}',\n",
        "    'train_label_examples':f'gs://{pathgcp_trainset}',\n",
        "    'test_examples':f'gs://{pathgcp_testset}'}\n",
        "\n",
        "generate_script_eval_args={\n",
        "    'project':GCP_PROJECT,\n",
        "    'location':GCP_LOCATION,\n",
        "    'job_type':'eval',\n",
        "    'display_name':GCP_EVALJOB_NAME,\n",
        "    'dataset_name':GCP_EXPERIMENT_NAME,\n",
        "    'eval_docker_image_uri_path':'gcr.io/disaster-assessment/ssl-eval-uri',\n",
        "    'service_account':service_account,\n",
        "    'train_dir':f'gs://{pathgcp_exper}',\n",
        "    'train_unlabel_examples':f'gs://{pathgcp_unlabeled}',\n",
        "    'train_label_examples':f'gs://{pathgcp_trainset}',\n",
        "    'test_examples':f'gs://{pathgcp_testset}'}\n",
        "\n",
        "if LOAD_TENSORBOARD=='Yes':\n",
        "  run_train_and_eval_job([generate_script_train_args,generate_script_eval_args],\n",
        "                       pathsys_args,\n",
        "                       EMAIL_MANAGER,\n",
        "                       sleep=[60],\n",
        "                       pretty_output=True,\n",
        "                       load_tensorboard=True,\n",
        "                       path_log_tensorboard=pathgcp_exper)\n",
        "else:\n",
        "  run_train_and_eval_job([generate_script_train_args,generate_script_eval_args],\n",
        "                       pathsys_args,\n",
        "                       EMAIL_MANAGER,\n",
        "                       sleep=[60],\n",
        "                       pretty_output=True)"
      ],
      "metadata": {
        "id": "-thHyb9JYM--",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXVMbL_PclUV"
      },
      "source": [
        "## Inference prediction 🔮\n",
        "\n",
        "Use the model and create the damage assessment. When it is done you will be shown the summary statistics for the disaster along with a map based visualization of the damaged buildings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Inference\n",
        "\n",
        "display(Javascript(\"google.colab.output.resizeIframeToContent()\"))\n",
        "\n",
        "#@markdown Enter a **experimentation job** selection option. If you don't chose \"runtime_saved\", please enter the specific name of the job you would like to use to run the inference.\n",
        "EXPER_JOB = \"runtine_saved\" #@param [\"runtine_saved\",\"name\"]\n",
        "JOB_NAME = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter a **evaluation job** selection option. If you don't chose \"runtime_saved\", please enter the specific name or id of the job you would like to use to run the inference.\n",
        "EVAL_JOB = \"runtine_saved\" #@param [\"runtine_saved\",\"name\",\"id\"]\n",
        "JOB_ID_NAME = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter a **checkpoint** selection option. If you chose \"index_number\", please enter the specific index of the checkpoint you would like to use to run the inference.\n",
        "MODEL_CHECKPOINT = \"most_recent\" #@param [\"most_recent\",\"top_auc_test\",\"top_acc_test\",\"index_number\"]\n",
        "INDEX_NUMBER = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if EXPER_JOB==\"name\":\n",
        "  GCP_EXPERIMENT_NAME=JOB_NAME\n",
        "elif EXPER_JOB==\"runtine_saved\":\n",
        "  if 'GCP_EXPERIMENT_NAME' not in locals():\n",
        "    raise Exception('''\n",
        "    Sorry, no Experiment job name is saved in your local runtine.\n",
        "    Please change selection option and specify name of your experiment job.''')\n",
        "pathgcp_exper=os.path.join(pathgcp_models, GCP_EXPERIMENT_NAME)\n",
        "\n",
        "if EVAL_JOB==\"id\":\n",
        "  GCP_EVAL_JOB=int(JOB_ID_NAME)\n",
        "elif EVAL_JOB==\"name\":\n",
        "  GCP_EVALJOB_NAME=JOB_ID_NAME\n",
        "  GCP_EVAL_JOB=get_train_eval_job_id(GCP_PROJECT,GCP_LOCATION, GCP_EVALJOB_NAME)\n",
        "elif EVAL_JOB==\"runtine_saved\":\n",
        "  if 'GCP_EVAL_JOB' not in locals():\n",
        "    if 'GCP_EVALJOB_NAME' in locals():\n",
        "      GCP_EVAL_JOB=get_train_eval_job_id(GCP_PROJECT,GCP_LOCATION, GCP_EVALJOB_NAME)\n",
        "    else:\n",
        "      raise Exception('''\n",
        "    Sorry, no Evaluation job id or name is saved in your local runtine.\n",
        "    Please change selection option and specify id or name of your evaluation job.''')\n",
        "\n",
        "epoch = get_epoch_number(pathgcp_exper,GCP_EVAL_JOB,MODEL_CHECKPOINT, INDEX_NUMBER)\n",
        "\n",
        "# Create inference script that will be run by child process.\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "GCP_INFERENCE_NAME=f\"{Author}_inference_{timestamp}_{Project_description}_default\"\n",
        "\n",
        "generate_script_infer_args={   \n",
        "    'project':GCP_PROJECT,\n",
        "    'location':GCP_LOCATION,\n",
        "    'eval_docker_image_uri_path':'gcr.io/disaster-assessment/ssl-eval-uri',\n",
        "    'service_account':service_account,\n",
        "    'dataset_name':GCP_EXPERIMENT_NAME,\n",
        "    'train_dir':'gs://'+pathgcp_exper,\n",
        "    'test_examples':'gs://'+pathgcp_unlabeled,\n",
        "    'display_name':GCP_INFERENCE_NAME,\n",
        "    'eval_ckpt': 'gs://'+pathgcp_exper+'/checkpoints/model.ckpt-'+epoch,\n",
        "    'eval_worker_machine_type':'n1-highmem-16',\n",
        "    'save_predictions':True,\n",
        "    'inference_mode':True,\n",
        "    'job_type':'eval'\n",
        "    }\n",
        "\n",
        "run_inference_and_prediction_job(generate_script_infer_args,\n",
        "                                 pathsys_args,\n",
        "                                 epoch,\n",
        "                                 pretty_output=True)"
      ],
      "metadata": {
        "id": "22PspX0hKnIX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize Inference\n",
        "\n",
        "display(Javascript(\"google.colab.output.resizeIframeToContent()\"))\n",
        "\n",
        "create_folium_map('/tmp/predictions.geojson',pathgcp_imagebefore, pathgcp_imageafter)"
      ],
      "metadata": {
        "id": "aKqYxTOA7vaB",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WXVMbL_PclUV"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}