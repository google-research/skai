{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZ4Nbz5x6Bw"
      },
      "source": [
        "#SKAI is the limit üöÄ\n",
        "*Assessing Post-Disaster Damage üèöÔ∏è from Satellite Imagery üõ∞Ô∏è using Semi-Supervised Learning Techniques üìî*\n",
        "\n",
        "*Contributors:  Amine Baha (1), Joseph Xu (2), Jihyeon Lee (2), Tomer Shekel (2), Fiona Huang (1)*\n",
        "\n",
        "*Co-developed by (1) WFP Innovation Accelerator and (2) Google Research AI, January 2023*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1IfnanckHeo"
      },
      "source": [
        "## Intro üèπ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAc_6ag50kyU"
      },
      "source": [
        "WFP partnered with Google Research to set up **SKAI**, a humanitarian response mapping solution powered by artificial intelligence ‚Äî an approach that combines statistical methods, data and modern computing techniques to automate specific tasks. SKAI assesses damage to buildings by applying computer vision ‚Äî computer algorithms that can interpret information extracted from visual materials such as, in this case, **satellite images of areas impacted by conflict, climate events, or other disasters**.\n",
        "\n",
        "![Skai Logo](https://storage.googleapis.com/skai-public/skai_logo.png)\n",
        "\n",
        "The type of machine learning used in SKAI, learns from a small number of labeled and a large number of unlabeled images of affected buildings. SKAI uses a ***semi-supervised learning technique*** that reduces the required number of labeled examples by an order of magnitude. As such, SKAI models typically *only need a couple hundred labeled examples* to achieve high accuracy, significantly improving the speed at which accurate results can be obtained.\n",
        "\n",
        "Google Research presented this novel application of semi-supervised learning (SSL) to train models for damage assessment with a minimal amount of labeled data and large amount of unlabeled data in [June 2020](https://ai.googleblog.com/2020/06/machine-learning-based-damage.html). Using the state-of-the-art methods including [MixMatch](https://arxiv.org/abs/1905.02249) and [FixMatch](https://arxiv.org/abs/2001.07685), they compare the performance with supervised baseline for the 2010 Haiti earthquake, 2017 Santa Rosa wildfire, and 2016 armed conflict in Syria.\n",
        "\n",
        "![SSL Approach](https://storage.googleapis.com/skai-public/ssl_diagram.png)\n",
        "\n",
        "The [paper](https://arxiv.org/abs/2011.14004) published by *Jihyeon Lee, Joseph Z. Xu, Kihyuk Sohn, Wenhan Lu, David Berthelot, Izzeddin Gur, Pranav Khaitan, Ke-Wei, Huang, Kyriacos Koupparis, Bernhard Kowatsch* shows how models trained with SSL methods can reach fully supervised performance despite using only a fraction of labeled data.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nihwE_UZFilS"
      },
      "source": [
        "## Notebook Setup üìì\n",
        "\n",
        "**Before running this Colab notebook, we recommend to initialize your kernel using [Initialize SKAI XManager Colab Kernel Notebook](https://github.com/google-research/skai/blob/main/src/colab/Initialize_SKAI_XManager_Colab_Kernel.ipynb).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tm86-tWoSZYJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "#@title Please run this cell first!\n",
        "\n",
        "#@markdown Specify the parameters to set up your Colab notebook. They should be the same that the ones used during the initialization of the Colab kernel\n",
        "#############################################\n",
        "### CODE SETTING - ENVIRONMENT ACTIVATION ###\n",
        "#############################################\n",
        "#@markdown ---\n",
        "#@markdown Please enter the path to the **git repository** and **colab workspace directory** to use:\n",
        "\n",
        "#@markdown ---\n",
        "SKAI_CODE_DIR = \"/content/skai\"  #@param {type:\"string\"}\n",
        "SKAI_VENV_DIR = \"/content/skai_env\"  #@param {type:\"string\"}\n",
        "SKAI_REPO = \"https://github.com/google-research/skai.git\"  #@param {type:\"string\"}\n",
        "SKAI_BRANCH = \"instadeep\"  #@param {type:\"string\"}\n",
        "SKAI_COMMIT = \"\" #@param {type:\"string\"}\n",
        "\n",
        "root_filesys=os.path.dirname(SKAI_CODE_DIR)\n",
        "\n",
        "pathsys_venv=SKAI_VENV_DIR\n",
        "pathsys_actenv=os.path.join(pathsys_venv, 'bin/activate')\n",
        "\n",
        "pathsys_skai=SKAI_CODE_DIR\n",
        "%shell rm -rf {SKAI_CODE_DIR}\n",
        "%shell git clone -b {SKAI_BRANCH} {SKAI_REPO} {SKAI_CODE_DIR}\n",
        "if SKAI_COMMIT!='':\n",
        "  %shell cd {SKAI_CODE_DIR} ; git checkout {SKAI_COMMIT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9vSAGvIiTMhq"
      },
      "outputs": [],
      "source": [
        "#@title Run XManager Train Job (with Vizier Hyperparameter Tuning) on Vertex AI\n",
        "\n",
        "#@markdown Enter arguments for the training job\n",
        "CONFIG_FILE = \"skai_two_tower_config\" #@param [\"skai_config\",\"skai_two_tower_config\"]\n",
        "DATASET_NAME = \"skai_dataset\" #@param {type:\"string\"}\n",
        "DATASET_GCP_PATH = \"gs://skai-data/hurricane_ian\" #@param {type:\"string\"}\n",
        "GCP_OUTPUT_DIR = \"gs://skai-data/experiments/skai_train_vizier\" #@param {type:\"string\"}\n",
        "NUM_EPOCHS = 10 #@param {type:\"integer\"}\n",
        "ACCELERATOR = \"V100\" #@param [\"V100\",\"T4\"]\n",
        "EXPERIMENT_NAME = \"skai_train_vizier\" #@param {type:\"string\"}\n",
        "\n",
        "GOOGLE_CLOUD_BUCKET_NAME = os.path.split(DATASET_GCP_PATH.replace(\"gs://\", \"\"))[0]\n",
        "\n",
        "\n",
        "job_args ={\n",
        "    'config':f\"src/skai/model/configs/{CONFIG_FILE}.py\",\n",
        "    'config.data.tfds_dataset_name':DATASET_NAME,\n",
        "    'config.data.tfds_data_dir':DATASET_GCP_PATH,\n",
        "    'config.output_dir':GCP_OUTPUT_DIR,\n",
        "    'config.training.num_epochs':NUM_EPOCHS,\n",
        "    'accelerator':ACCELERATOR,\n",
        "    'experiment_name':EXPERIMENT_NAME,\n",
        "}\n",
        "\n",
        "JOB_ARGS_STR = [' '.join(f\"--{f}={v}\" for f, v in job_args.items())][0]\n",
        "\n",
        "print(JOB_ARGS_STR)\n",
        "\n",
        "sh = f\"\"\"\n",
        "export GOOGLE_APPLICATION_CREDENTIALS=/root/service-account-private-key.json\n",
        "export GOOGLE_CLOUD_BUCKET_NAME={GOOGLE_CLOUD_BUCKET_NAME}\n",
        "\n",
        "cd {SKAI_CODE_DIR}\n",
        "xmanager launch src/skai/model/xm_launch_single_model_vertex.py -- \\\n",
        "--xm_wrap_late_bindings \\\n",
        "--xm_upgrade_db=True \\\n",
        "--project_path={SKAI_CODE_DIR} \\\n",
        "--accelerator_count=1 {JOB_ARGS_STR}\n",
        "\"\"\"\n",
        "\n",
        "with open('script.sh', 'w') as file:\n",
        "  file.write(sh)\n",
        "\n",
        "%shell bash script.sh"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WXVMbL_PclUV"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
