{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/google-research/skai/blob/skai-colab-0000004/src/colab/Run_SKAI_Colab_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZ4Nbz5x6Bw"
      },
      "source": [
        "#SKAI is the limit üöÄ\n",
        "*Assessing Post-Disaster Damage üèöÔ∏è from Satellite Imagery üõ∞Ô∏è using Semi-Supervised Learning Techniques üìî*\n",
        "\n",
        "*Contributors:  Amine Baha (1), Joseph Xu (2), Jihyeon Lee (2), Tomer Shekel (2), Fiona Huang (1)*\n",
        "\n",
        "*Co-developed by (1) WFP Innovation Accelerator and (2) Google Research AI, January 2023*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1IfnanckHeo"
      },
      "source": [
        "## Intro üèπ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAc_6ag50kyU"
      },
      "source": [
        "WFP partnered with Google Research to set up **SKAI**, a humanitarian response mapping solution powered by artificial intelligence ‚Äî an approach that combines statistical methods, data and modern computing techniques to automate specific tasks. SKAI assesses damage to buildings by applying computer vision ‚Äî computer algorithms that can interpret information extracted from visual materials such as, in this case, **satellite images of areas impacted by conflict, climate events, or other disasters**.\n",
        "\n",
        "![Skai Logo](https://storage.googleapis.com/skai-public/skai_logo.png)\n",
        "\n",
        "The type of machine learning used in SKAI, learns from a small number of labeled and a large number of unlabeled images of affected buildings. SKAI uses a ***semi-supervised learning technique*** that reduces the required number of labeled examples by an order of magnitude. As such, SKAI models typically *only need a couple hundred labeled examples* to achieve high accuracy, significantly improving the speed at which accurate results can be obtained.\n",
        "\n",
        "Google Research presented this novel application of semi-supervised learning (SSL) to train models for damage assessment with a minimal amount of labeled data and large amount of unlabeled data in [June 2020](https://ai.googleblog.com/2020/06/machine-learning-based-damage.html). Using the state-of-the-art methods including [MixMatch](https://arxiv.org/abs/1905.02249) and [FixMatch](https://arxiv.org/abs/2001.07685), they compare the performance with supervised baseline for the 2010 Haiti earthquake, 2017 Santa Rosa wildfire, and 2016 armed conflict in Syria.\n",
        "\n",
        "![SSL Approach](https://storage.googleapis.com/skai-public/ssl_diagram.png)\n",
        "\n",
        "The [paper](https://arxiv.org/abs/2011.14004) published by *Jihyeon Lee, Joseph Z. Xu, Kihyuk Sohn, Wenhan Lu, David Berthelot, Izzeddin Gur, Pranav Khaitan, Ke-Wei, Huang, Kyriacos Koupparis, Bernhard Kowatsch* shows how models trained with SSL methods can reach fully supervised performance despite using only a fraction of labeled data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nihwE_UZFilS"
      },
      "source": [
        "## Notebook Setup üìì\n",
        "\n",
        "**Please refer to the [SKAI Colab Notebooks Instructions](/docs/colab_instructions.md) before running this Colab notebook.**\n",
        "**Before running this Colab notebook, we recommend to initialize your kernel using [Initialize SKAI Colab Kernel Notebook](https://github.com/google-research/skai/blob/main/src/colab/Initialize_SKAI_Colab_Kernel.ipynb).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tm86-tWoSZYJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "#@title Please run this cell first!\n",
        "\n",
        "#@markdown Specify the parameters to set up your Colab notebook. They should be the same that the ones used during the initialization of the Colab kernel\n",
        "#############################################\n",
        "### CODE SETTING - ENVIRONMENT ACTIVATION ###\n",
        "#############################################\n",
        "#@markdown ---\n",
        "#@markdown Please enter the path to the **git repository** and **colab workspace directory** to use:\n",
        "\n",
        "#@markdown ---\n",
        "SKAI_CODE_DIR = \"/content/skai_src\"  #@param {type:\"string\"}\n",
        "SKAI_VENV_DIR = \"/content/skai_env\"  #@param {type:\"string\"}\n",
        "SKAI_REPO = \"https://github.com/google-research/skai.git\"  #@param {type:\"string\"}\n",
        "SKAI_BRANCH = \"main\"  #@param {type:\"string\"}\n",
        "SKAI_COMMIT = \"\" #@param {type:\"string\"}\n",
        "\n",
        "root_filesys=os.path.dirname(SKAI_CODE_DIR)\n",
        "\n",
        "pathsys_venv=SKAI_VENV_DIR\n",
        "pathsys_actenv=os.path.join(pathsys_venv, 'bin/activate')\n",
        "\n",
        "pathsys_skai=SKAI_CODE_DIR\n",
        "%shell rm -rf {SKAI_CODE_DIR}\n",
        "%shell git clone -b {SKAI_BRANCH} {SKAI_REPO} {SKAI_CODE_DIR}\n",
        "if SKAI_COMMIT!='':\n",
        "  %shell cd {SKAI_CODE_DIR} ; git checkout {SKAI_COMMIT}\n",
        "\n",
        "%cd {SKAI_CODE_DIR}/src/colab\n",
        "import colab_utils\n",
        "from colab_utils import *\n",
        "\n",
        "def load_start_tensorboard(path_log):\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir gs://{path_log}\n",
        "\n",
        "colab_utils.load_start_tensorboard=load_start_tensorboard\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dDtCZ5QvYBom"
      },
      "outputs": [],
      "source": [
        "#@title Input project parameters\n",
        "\n",
        "#@markdown Specify the variables to set your damage assessment project and press play:\n",
        "#############################################\n",
        "### INITIAL SETTING - PROJECT DESCRIPTION ###\n",
        "#############################################\n",
        "#@markdown ---\n",
        "#@markdown Please enter here the parameters for your **disaster assessment project desciption:**\n",
        "\n",
        "#@markdown ---\n",
        "Disaster = 'Cyclone' #@param [\"Cyclone\", \"Earthquake\", \"Tsunami\", \"Flood\", \"Eruption\", \"Tornado\", \"Wind\", \"Wildfire\", \"Landslide\", \"Conflict\"]\n",
        "Year =  None #@param {type:\"integer\"}\n",
        "Month =  None #@param {type:\"integer\"}\n",
        "Name = '' #@param {type:\"string\"}\n",
        "Country = '' #@param {type:\"string\"}\n",
        "Organisation = '' #@param {type:\"string\"}\n",
        "Run = '' #@param {type:\"string\"}\n",
        "\n",
        "PROJECT_DIRECTORY=f\"{Organisation}-{Disaster}-{Name}-{Country}-{Year}{Month:02d}\"\n",
        "if not Run.isspace() and Run!=\"\":\n",
        "  PROJECT_DIRECTORY=f'{PROJECT_DIRECTORY}_{Run}'\n",
        "PROJECT_DIRECTORY=f'{PROJECT_DIRECTORY}'.lower()\n",
        "\n",
        "\n",
        "####################################################\n",
        "### CLOUD SETTING - PROJECT/BUCKET CONFIGURATION ###\n",
        "####################################################\n",
        "#@markdown ---\n",
        "#@markdown Please enter the parameters of **google cloud platform account** to use:\n",
        "\n",
        "#@markdown ---\n",
        "GCP_PROJECT = \"\" #@param {type:\"string\"}\n",
        "GCP_LOCATION = \"\" #@param {type:\"string\"}\n",
        "GCP_SERVICE_ACCOUNT=\"\"#@param {type:\"string\"}\n",
        "\n",
        "GCP_LOCATION_LABELING=GCP_LOCATION\n",
        "if \"europe-\" in GCP_LOCATION :\n",
        "  GCP_LOCATION_LABELING= \"europe-west4\"\n",
        "  if GCP_LOCATION!= \"europe-west1\" :\n",
        "    GCP_LOCATION= \"europe-west1\"\n",
        "    print(f\"\\nLocation region has been changed to {GCP_LOCATION} (Vertex AI features availability) \")\n",
        "if \"us-\" in GCP_LOCATION :\n",
        "  GCP_LOCATION_LABELING= \"us-central1\"\n",
        "  if GCP_LOCATION!= \"us-central1\" :\n",
        "    GCP_LOCATION= \"us-central1\"\n",
        "    print(f\"\\nLocation region has been changed to {GCP_LOCATION} (Vertex AI features availability) \")\n",
        "\n",
        "GCP_PROJECT_ID=get_project_id(GCP_PROJECT)\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Please enter the parameters of **google cloud bucket** to create your working folder into your GCP project, named as\n",
        "\n",
        "#@markdown *\\<GCP_PROJECT>*colab_bucket_*\\<BCKT_VERSION>*_*\\<Author>*\n",
        "\n",
        "#@markdown A specific folder for your disaster assessment project will be created under this bucket.\n",
        "\n",
        "Tool=\"Colab\"\n",
        "\n",
        "#@markdown ---\n",
        "BCKT_VERSION = \"\" #@param {type:\"string\"}\n",
        "Author = '' #@param {type:\"string\"}\n",
        "\n",
        "GCP_BUCKET = f\"{GCP_PROJECT}_{Tool}_Bucket\"\n",
        "if not BCKT_VERSION.isspace() and BCKT_VERSION!=\"\":\n",
        "  GCP_BUCKET=f'{GCP_BUCKET}_{BCKT_VERSION}'\n",
        "if not Author.isspace() and Author!=\"\":\n",
        "  GCP_BUCKET=f'{GCP_BUCKET}_{Author}'\n",
        "\n",
        "GCP_BUCKET = GCP_BUCKET.lower()\n",
        "\n",
        "if not bucket_exists(GCP_PROJECT, GCP_BUCKET):\n",
        "  create_bucket(GCP_PROJECT, GCP_LOCATION, GCP_BUCKET)\n",
        "\n",
        "print(f\"\\nYour project bucket in Google Cloud: {GCP_BUCKET} \\nhttps://console.cloud.google.com/storage/browser/{GCP_BUCKET}\")\n",
        "print(f\"\\nYour project folder: {PROJECT_DIRECTORY}\")\n",
        "\n",
        "pathgcp_outputdir=os.path.join(GCP_BUCKET,PROJECT_DIRECTORY)\n",
        "\n",
        "service_account = GCP_SERVICE_ACCOUNT\n",
        "pathsys_credentials = '/root/service-account-private-key.json'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = pathsys_credentials\n",
        "\n",
        "# Prepare credentials for map visualization.\n",
        "credentials = ee.ServiceAccountCredentials(service_account, pathsys_credentials)\n",
        "#Register the service account : https://signup.earthengine.google.com/#!/service_accounts\n",
        "ee.Initialize(credentials)\n",
        "\n",
        "pathsys_args={\n",
        "    'python_env':pathsys_actenv,\n",
        "    'path_skai':pathsys_skai,\n",
        "    'path_cred':pathsys_credentials\n",
        "}\n",
        "\n",
        "#########################################\n",
        "### IMAGE SETTING - FILE & DIRECTORY ###\n",
        "#########################################\n",
        "#@markdown ---\n",
        "#@markdown Please enter the path to the files of **pre and post disaster satellite images** and **area of interest** you previously uploaded to your GCP project:\n",
        "\n",
        "#@markdown ---\n",
        "#IMAGERY_INPUT = \"mosaic_images\" #@param [\"single_image\", \"mosaic_images\"]\n",
        "FILE_IMAGE_BEFORE = 'gs://bucket_path/*_Pre.tif' #@param {type:\"string\"}\n",
        "FILE_IMAGE_AFTER = 'gs://bucket_path/*_Post.tif' #@param {type:\"string\"}\n",
        "#@markdown Provide prefix of image filenames (replacing * in previous input), separated by commas (e.g. *Area1,Area2,Area3*). If consider all files, leave blank.\n",
        "IMAGE_PREFIX_BEFORE = '' #@param {type:\"string\"}\n",
        "IMAGE_PREFIX_AFTER = '' #@param {type:\"string\"}\n",
        "FILE_IMAGE_AOI = 'gs://bucket_path/*.geojson' #@param {type:\"string\"}\n",
        "#@markdown If you chose to use labeled file, please enter path to file, key and mapping to use:\n",
        "FILE_IMAGE_LABELED = '' #@param {type:\"string\"}\n",
        "KEY_IMAGE_LABELED = \"\" #@param {type:\"string\"}\n",
        "MAPPING_IMAGE_LABELED = '' #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown Choose where to get **building footprints** from:\n",
        "BUILDING_DETECTION_METHOD = \"open_buildings\" #@param [\"open_buildings\",\"open_street_map\",\"file\"]\n",
        "#@markdown If you chose \"file\", please enter path to CSV file here:\n",
        "BUILDINGS_CSV = '' #@param {type:\"string\"}\n",
        "\n",
        "pathgcp_imagesource=os.path.dirname(FILE_IMAGE_BEFORE).replace('gs://','')\n",
        "pathgcp_images=os.path.join(pathgcp_outputdir,'images')\n",
        "\n",
        "\n",
        "if IMAGE_PREFIX_BEFORE=='':\n",
        "  file_path_split=FILE_IMAGE_BEFORE.split('/')\n",
        "  name_pattern='/'.join(file_path_split[3:])\n",
        "  name_folder='/'.join(file_path_split[3:][:-1])+'/'\n",
        "  url='https://storage.googleapis.com/storage/v1/b/{}/o'.format(file_path_split[2])\n",
        "  data = make_gcp_http_request(url)\n",
        "  IMAGE_PREFIX_BEFORE=','.join([re.search(name_pattern.replace('*','(.*)'),d['name']).group(1) for d in data['items'] if d['name']!= name_folder and re.search(name_pattern.replace('*','(.*)'),d['name'])])\n",
        "\n",
        "pathgcp_imagebefore=[FILE_IMAGE_BEFORE.replace('*',prefix.strip()) for prefix in IMAGE_PREFIX_BEFORE.split(',')]\n",
        "pathgcp_imagebefore= ','.join(pathgcp_imagebefore)\n",
        "\n",
        "if IMAGE_PREFIX_AFTER=='':\n",
        "  file_path_split=FILE_IMAGE_AFTER.split('/')\n",
        "  name_pattern='/'.join(file_path_split[3:])\n",
        "  name_folder='/'.join(file_path_split[3:][:-1])+'/'\n",
        "  url='https://storage.googleapis.com/storage/v1/b/{}/o'.format(file_path_split[2])\n",
        "  data = make_gcp_http_request(url)\n",
        "  IMAGE_PREFIX_AFTER=','.join([re.search(name_pattern.replace('*','(.*)'),d['name']).group(1) for d in data['items'] if d['name']!= name_folder and re.search(name_pattern.replace('*','(.*)'),d['name'])])\n",
        "\n",
        "pathgcp_imageafter=[FILE_IMAGE_AFTER.replace('*',prefix.strip()) for prefix in IMAGE_PREFIX_AFTER.split(',')]\n",
        "pathgcp_imageafter= ','.join(pathgcp_imageafter)\n",
        "\n",
        "pathgcp_aoi=FILE_IMAGE_AOI\n",
        "pathgcp_filelabeled=FILE_IMAGE_LABELED\n",
        "pathgcp_keylabeled=KEY_IMAGE_LABELED\n",
        "pathgcp_mappinglabeled=MAPPING_IMAGE_LABELED\n",
        "\n",
        "#########################################\n",
        "### EXAMPLE SETTING - CLOUD DIRECTORY ###\n",
        "#########################################\n",
        "pathgcp_examples=os.path.join(pathgcp_outputdir,'examples')\n",
        "pathgcp_pattern=os.path.join(pathgcp_examples,'unlabeled-large/*.tfrecord')\n",
        "pathgcp_importfolder=os.path.join(pathgcp_examples,'labeling_images')\n",
        "pathgcp_importfile=os.path.join(pathgcp_importfolder,'import_file.csv')\n",
        "\n",
        "###########################################\n",
        "### LABELING SETTING - EMAIL PARAMETERS ###\n",
        "###########################################\n",
        "#@markdown ---\n",
        "#@markdown Provide **email addresses** for all individuals that will help with labeling images, separated by commas.\n",
        "#@markdown Emails of the labelers need to be linked to a google account.\n",
        "#@markdown E.g. *manager@gmail.com* and *annotator1@gmail.com,annotator2@gmail.com*\n",
        "\n",
        "#@markdown ---\n",
        "EMAIL_MANAGER = '' #@param {type:\"string\"}\n",
        "EMAIL_ANNOTATORS = '' #@param {type:\"string\"}\n",
        "\n",
        "if EMAIL_MANAGER.strip() in EMAIL_ANNOTATORS:\n",
        "  EMAIL_ANNOTATORS.replace(EMAIL_MANAGER.strip(), '')\n",
        "GCP_LABELER_EMAIL = [EMAIL_MANAGER.strip()] + [email.strip() for email in EMAIL_ANNOTATORS.split(',')]\n",
        "GCP_LABELER_EMAIL = ','.join(GCP_LABELER_EMAIL)\n",
        "\n",
        "################################################\n",
        "### DATASET SETTING - FILE & CLOUD DIRECTORY ###\n",
        "################################################\n",
        "pathgcp_temp=os.path.join(pathgcp_outputdir,'temp')\n",
        "pathgcp_unlabeled=os.path.join(pathgcp_examples,'unlabeled/*.tfrecord')\n",
        "\n",
        "pathgcp_trainset=os.path.join(pathgcp_examples,'labeled_train_examples.tfrecord')\n",
        "pathgcp_testset=os.path.join(pathgcp_examples,'labeled_test_examples.tfrecord')\n",
        "\n",
        "#######################################\n",
        "### MODEL SETTING - FILE & DIRECTORY ##\n",
        "#######################################\n",
        "pathsys_runjobs=os.path.join(root_filesys,'run_jobs')\n",
        "if not os.path.exists(pathsys_runjobs):\n",
        "  os.mkdir(pathsys_runjobs)\n",
        "\n",
        "pathgcp_models=os.path.join(pathgcp_outputdir,'models')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esh2w1R5AAJy"
      },
      "source": [
        "## Data labeling üë∑\n",
        "\n",
        "Create examples of buildings images before and after the disaster and classify them as either undamaged, possibly damaged, damaged/destroyed, or bad example (e.g., cloud cover etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2rqwIPUfjq4H"
      },
      "outputs": [],
      "source": [
        "#@title Visualize before and after images\n",
        "\n",
        "display(Javascript(\"google.colab.output.resizeIframeToContent()\"))\n",
        "create_folium_map_with_images(pathgcp_imagebefore, pathgcp_imageafter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "UQCV3QSW2Y0C"
      },
      "outputs": [],
      "source": [
        "#@title Generate Examples\n",
        "#@markdown First, generate the building images. This task should take about 30-45 minutes.\n",
        "\n",
        "#@markdown Select if you want to generate your example from a labeled file or generate unlabeled examples.\n",
        "GENERATING_JOB = \"labeled\" #@param [\"labeled\",\"unlabeled\"]\n",
        "\n",
        "## COMMAND RUN\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "GCP_DATASET_NAME = f\"{Author}_example_{timestamp}_{PROJECT_DIRECTORY}\".replace(\"_\",\"-\").lower()\n",
        "\n",
        "if GENERATING_JOB == \"labeled\":\n",
        "  generate_examples_args = {\n",
        "    'cloud_project': GCP_PROJECT,\n",
        "    'cloud_region': GCP_LOCATION,\n",
        "    'dataset_name' : GCP_DATASET_NAME,\n",
        "    'before_image_patterns': pathgcp_imagebefore,\n",
        "    'after_image_patterns': pathgcp_imageafter,\n",
        "    'aoi_path': pathgcp_aoi,\n",
        "    'output_dir': f'gs://{pathgcp_outputdir}',\n",
        "    'buildings_method': 'none',\n",
        "    'worker_service_account': service_account,\n",
        "    'earth_engine_service_account' : service_account,\n",
        "    'earth_engine_private_key' : pathsys_credentials,\n",
        "    'use_dataflow': 'true',\n",
        "    'labels_file': pathgcp_filelabeled,\n",
        "    'label_property': pathgcp_keylabeled,\n",
        "    'labels_to_classes': pathgcp_mappinglabeled\n",
        "    }\n",
        "\n",
        "else:\n",
        "  generate_examples_args = {\n",
        "    'cloud_project': GCP_PROJECT,\n",
        "    'cloud_region': GCP_LOCATION,\n",
        "    'dataset_name' : GCP_DATASET_NAME,\n",
        "    'before_image_patterns': pathgcp_imagebefore,\n",
        "    'after_image_patterns': pathgcp_imageafter,\n",
        "    'aoi_path': pathgcp_aoi,\n",
        "    'output_dir': f'gs://{pathgcp_outputdir}',\n",
        "    'buildings_method': BUILDING_DETECTION_METHOD,\n",
        "    'buildings_file': BUILDINGS_CSV,\n",
        "    'worker_service_account': service_account,\n",
        "    'earth_engine_service_account' : service_account,\n",
        "    'earth_engine_private_key' : pathsys_credentials,\n",
        "    'use_dataflow': 'true',\n",
        "    }\n",
        "\n",
        "\n",
        "run_example_generation(generate_examples_args,pathsys_args,pretty_output=True)\n",
        "print(f\"\\nGenerated examples are saved in the folder :\\n{generate_examples_args['output_dir']}/examples\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "X4IvDFtsD-cV"
      },
      "outputs": [],
      "source": [
        "#@title Create Labeling Task\n",
        "\n",
        "#@markdown Second, create the labeling tasks for the labelers. This task should take about 15-30 minutes.\n",
        "\n",
        "#@markdown At the end of this step you and each labelers will receive an email with the instruction on how to perform the labeling task.\n",
        "\n",
        "#@markdown Enter the maximum number of images to label (by default, 1000) :\n",
        "MAX_IMAGES = 1000 #@param {type:\"integer\"}\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "GCP_DATASET_NAME = f\"{Author}_label_{timestamp}_{PROJECT_DIRECTORY}\".lower()\n",
        "if MAX_IMAGES==0 or MAX_IMAGES is None:\n",
        "  MAX_IMAGES=1000\n",
        "\n",
        "create_labeling_task_args = {\n",
        "    'cloud_project':GCP_PROJECT,\n",
        "    'cloud_location':GCP_LOCATION_LABELING,\n",
        "    'dataset_name': GCP_DATASET_NAME,\n",
        "    'examples_pattern': f'gs://{pathgcp_pattern}',\n",
        "    'images_dir':  f'gs://{pathgcp_importfolder}',\n",
        "    'cloud_labeler_emails': GCP_LABELER_EMAIL,\n",
        "    'max_images':MAX_IMAGES\n",
        "    }\n",
        "\n",
        "GCP_DATASET_ID ,GCP_DATASET_NAME,GCP_LABELING_JOB,GCP_LABELING_INSTRUCTION = run_labeling_task_creation(create_labeling_task_args,pathsys_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qSwaYjKLDry9"
      },
      "outputs": [],
      "source": [
        "#@title Monitor Labeling Task\n",
        "\n",
        "#@markdown As a manager of the task, you can track the labeling progress by running this script below and see how many labels were created or view the detailed monitoring page.\n",
        "\n",
        "#@markdown For good quality we recommend having about 200-300 building labels from the damaged/destroyed and undamaged categories.\n",
        "\n",
        "#@markdown Enter a **labeling job** selection option. If you don't chose \"runtime_saved\", please enter the specific id of the job you would like to monitor.\n",
        "LABELING_JOB = \"runtime_saved\" #@param [\"runtime_saved\",\"id\"]\n",
        "JOB_ID = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if LABELING_JOB==\"id\":\n",
        "  GCP_LABELING_JOB=int(JOB_ID)\n",
        "elif LABELING_JOB==\"runtime_saved\":\n",
        "  if 'GCP_LABELING_JOB' not in locals():\n",
        "    raise Exception('''\n",
        "    Sorry, no Data Labeling job id is saved in your local runtine.\n",
        "    Please change selection option and specify id of your data labeling job.''')\n",
        "\n",
        "labeling_job = LabelingJob(f'{GCP_LOCATION_LABELING}-aiplatform.googleapis.com',\n",
        "                           GCP_PROJECT, GCP_LOCATION_LABELING, GCP_LABELING_JOB)\n",
        "print(f'\\nJob completion percentage: {labeling_job.get_completion_percentage()}% (Data Labeling job ID {GCP_LABELING_JOB})')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulMjwGaex8LK"
      },
      "source": [
        "## Training and evaluation datasets üß©\n",
        "\n",
        "Assign the labeled images to training and evaluation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9vSAGvIiTMhq"
      },
      "outputs": [],
      "source": [
        "#@title Create training and evaluation datasets\n",
        "\n",
        "#@markdown Enter a **labeling dataset** selection option. If you don't chose \"runtime_saved\", please enter the specific id of the dataset you would like to create your datasets.\n",
        "LABELING_DATASET = \"runtime_saved\" #@param [\"runtime_saved\",\"id\"]\n",
        "DATASET_ID = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if LABELING_DATASET==\"id\":\n",
        "  GCP_DATASET_ID=DATASET_ID\n",
        "elif LABELING_DATASET==\"runtime_saved\":\n",
        "  if 'GCP_DATASET_ID' not in locals():\n",
        "    raise Exception('''\n",
        "    Sorry, no Labeling dataset id is saved in your local runtine.\n",
        "    Please change selection option and specify id of your labeling dataset.''')\n",
        "\n",
        "create_labeled_dataset_args = {\n",
        "    'cloud_project':GCP_PROJECT,\n",
        "    'cloud_location':GCP_LOCATION_LABELING,\n",
        "    'cloud_dataset_id': GCP_DATASET_ID,\n",
        "    \"cloud_temp_dir\": f'gs://{pathgcp_temp}',\n",
        "    \"examples_pattern\": f'gs://{pathgcp_unlabeled}',\n",
        "    \"train_output_path\": f'gs://{pathgcp_trainset}',\n",
        "    \"test_output_path\": f'gs://{pathgcp_testset}'}\n",
        "\n",
        "create_labeled_dataset(create_labeled_dataset_args,pathsys_args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ehjrJ1keXeJ"
      },
      "source": [
        "### Inspect training and evaluation datasets (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "K10K2imWSEcE"
      },
      "outputs": [],
      "source": [
        "#@title Inspect the training dataset (optional)\n",
        "\n",
        "## COMMAND RUN\n",
        "COUNT_TRAIN_LABELED=visualize_labeled_examples(os.path.join(\"gs://\",pathgcp_trainset),max_examples=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FfUy0Ympl4ko"
      },
      "outputs": [],
      "source": [
        "#@title Inspect the evaluation dataset (optional)\n",
        "\n",
        "COUNT_TEST_LABELED=visualize_labeled_examples(os.path.join(\"gs://\",pathgcp_testset),max_examples=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0pTjiIeB-w"
      },
      "source": [
        "## Model training, performance evaluation ü§ñ\n",
        "\n",
        "Train the machine learning model and test it using the evaluation dataset (leveraging the examples you previously labeled).\n",
        "\n",
        "The script runs in the background and may take up to 6 hours. You will be able to see the progress on this page and we will also send you an email when this step is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-thHyb9JYM--"
      },
      "outputs": [],
      "source": [
        "#@title Train and evaluate model\n",
        "\n",
        "display(Javascript(\"google.colab.output.resizeIframeToContent()\"))\n",
        "\n",
        "#@markdown Select if you want to train a model on supervised or semi-supervised learning approach.\n",
        "LEARNING_METHOD = \"semi_supervised\" #@param [\"fully_supervised\",\"semi_supervised\"]\n",
        "\n",
        "#@markdown View Results in Tensorboard:\n",
        "LOAD_TENSORBOARD = 'Yes' #@param [\"Yes\",\"No\"]\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "GCP_EXPERIMENT_NAME=f\"{Author}_experiment_{timestamp}_{PROJECT_DIRECTORY}_default\".lower()\n",
        "GCP_TRAINJOB_NAME=f\"{Author}_train_{timestamp}_{PROJECT_DIRECTORY}_default\".lower()\n",
        "GCP_EVALJOB_NAME=f\"{Author}_eval_{timestamp}_{PROJECT_DIRECTORY}_default\".lower()\n",
        "\n",
        "pathgcp_exper=os.path.join(pathgcp_models, GCP_EXPERIMENT_NAME)\n",
        "\n",
        "generate_script_train_args={\n",
        "    'project':GCP_PROJECT,\n",
        "    'location':GCP_LOCATION,\n",
        "    'job_type':'train',\n",
        "    'display_name':GCP_TRAINJOB_NAME,\n",
        "    'dataset_name':GCP_EXPERIMENT_NAME,\n",
        "    'train_worker_machine_type':'n1-highmem-16',\n",
        "    'train_docker_image_uri_path':'gcr.io/disaster-assessment/ssl-train-uri',\n",
        "    'service_account':service_account,\n",
        "    'train_dir':f'gs://{pathgcp_exper}',\n",
        "    'train_unlabel_examples':f'gs://{pathgcp_unlabeled}',\n",
        "    'train_label_examples':f'gs://{pathgcp_trainset}',\n",
        "    'test_examples':f'gs://{pathgcp_testset}'}\n",
        "\n",
        "generate_script_eval_args={\n",
        "    'project':GCP_PROJECT,\n",
        "    'location':GCP_LOCATION,\n",
        "    'job_type':'eval',\n",
        "    'display_name':GCP_EVALJOB_NAME,\n",
        "    'dataset_name':GCP_EXPERIMENT_NAME,\n",
        "    'eval_docker_image_uri_path':'gcr.io/disaster-assessment/ssl-eval-uri',\n",
        "    'service_account':service_account,\n",
        "    'train_dir':f'gs://{pathgcp_exper}',\n",
        "    'train_unlabel_examples':f'gs://{pathgcp_unlabeled}',\n",
        "    'train_label_examples':f'gs://{pathgcp_trainset}',\n",
        "    'test_examples':f'gs://{pathgcp_testset}'}\n",
        "\n",
        "if LEARNING_METHOD == \"fully_supervised\":\n",
        "  generate_script_train_args['method']='fully_supervised'\n",
        "  generate_script_eval_args['method']='fully_supervised'\n",
        "\n",
        "if LOAD_TENSORBOARD=='Yes':\n",
        "  run_train_and_eval_job([generate_script_train_args,generate_script_eval_args],\n",
        "                       pathsys_args,\n",
        "                       EMAIL_MANAGER,\n",
        "                       sleep=[60],\n",
        "                       pretty_output=True,\n",
        "                       load_tensorboard=True,\n",
        "                       path_log_tensorboard=pathgcp_exper)\n",
        "else:\n",
        "  run_train_and_eval_job([generate_script_train_args,generate_script_eval_args],\n",
        "                       pathsys_args,\n",
        "                       EMAIL_MANAGER,\n",
        "                       sleep=[60],\n",
        "                       pretty_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXVMbL_PclUV"
      },
      "source": [
        "## Inference prediction üîÆ\n",
        "\n",
        "Use the model and create the damage assessment. When it is done you will be shown the summary statistics for the disaster along with a map based visualization of the damaged buildings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "22PspX0hKnIX"
      },
      "outputs": [],
      "source": [
        "#@title Run Inference\n",
        "\n",
        "display(Javascript(\"google.colab.output.resizeIframeToContent()\"))\n",
        "\n",
        "#@markdown Enter a **experimentation job** selection option. If you don't chose \"runtime_saved\", please enter the specific name of the job you would like to use to run the inference.\n",
        "EXPER_JOB = \"runtine_saved\" #@param [\"runtine_saved\",\"name\"]\n",
        "JOB_NAME = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter a **evaluation job** selection option. If you don't chose \"runtime_saved\", please enter the specific name or id of the job you would like to use to run the inference.\n",
        "EVAL_JOB = \"runtine_saved\" #@param [\"runtine_saved\",\"name\",\"id\"]\n",
        "JOB_ID_NAME = \"\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter a **checkpoint** selection option. If you chose \"index_number\", please enter the specific index of the checkpoint you would like to use to run the inference.\n",
        "MODEL_CHECKPOINT = \"most_recent\" #@param [\"most_recent\",\"top_auc_test\",\"top_acc_test\",\"index_number\"]\n",
        "INDEX_NUMBER = \"\" #@param {type:\"string\"}\n",
        "\n",
        "if EXPER_JOB==\"name\":\n",
        "  GCP_EXPERIMENT_NAME=JOB_NAME\n",
        "elif EXPER_JOB==\"runtine_saved\":\n",
        "  if 'GCP_EXPERIMENT_NAME' not in locals():\n",
        "    raise Exception('''\n",
        "    Sorry, no Experiment job name is saved in your local runtine.\n",
        "    Please change selection option and specify name of your experiment job.''')\n",
        "pathgcp_exper=os.path.join(pathgcp_models, GCP_EXPERIMENT_NAME)\n",
        "\n",
        "if EVAL_JOB==\"id\":\n",
        "  GCP_EVAL_JOB=int(JOB_ID_NAME)\n",
        "elif EVAL_JOB==\"name\":\n",
        "  GCP_EVALJOB_NAME=JOB_ID_NAME\n",
        "  GCP_EVAL_JOB=get_train_eval_job_id(GCP_PROJECT,GCP_LOCATION, GCP_EVALJOB_NAME)\n",
        "elif EVAL_JOB==\"runtine_saved\":\n",
        "  if 'GCP_EVAL_JOB' not in locals():\n",
        "    if 'GCP_EVALJOB_NAME' in locals():\n",
        "      GCP_EVAL_JOB=get_train_eval_job_id(GCP_PROJECT,GCP_LOCATION, GCP_EVALJOB_NAME)\n",
        "    else:\n",
        "      raise Exception('''\n",
        "    Sorry, no Evaluation job id or name is saved in your local runtine.\n",
        "    Please change selection option and specify id or name of your evaluation job.''')\n",
        "\n",
        "epoch = get_epoch_number(pathgcp_exper,GCP_EVAL_JOB,MODEL_CHECKPOINT, INDEX_NUMBER)\n",
        "\n",
        "# Create inference script that will be run by child process.\n",
        "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "GCP_INFERENCE_NAME=f\"{Author}_inference_{timestamp}_{PROJECT_DIRECTORY}_default\".lower()\n",
        "\n",
        "generate_script_infer_args={\n",
        "    'project':GCP_PROJECT,\n",
        "    'location':GCP_LOCATION,\n",
        "    'eval_docker_image_uri_path':'gcr.io/disaster-assessment/ssl-eval-uri',\n",
        "    'service_account':service_account,\n",
        "    'dataset_name':GCP_EXPERIMENT_NAME,\n",
        "    'train_dir':'gs://'+pathgcp_exper,\n",
        "    'test_examples':'gs://'+pathgcp_unlabeled,\n",
        "    'display_name':GCP_INFERENCE_NAME,\n",
        "    'eval_ckpt': 'gs://'+pathgcp_exper+'/checkpoints/model.ckpt-'+epoch,\n",
        "    'eval_worker_machine_type':'n1-highmem-16',\n",
        "    'save_predictions':True,\n",
        "    'inference_mode':True,\n",
        "    'job_type':'eval'\n",
        "    }\n",
        "\n",
        "run_inference_and_prediction_job(generate_script_infer_args,\n",
        "                                 pathsys_args,\n",
        "                                 epoch,\n",
        "                                 pretty_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aKqYxTOA7vaB"
      },
      "outputs": [],
      "source": [
        "#@title Visualize Inference\n",
        "\n",
        "display(Javascript(\"google.colab.output.resizeIframeToContent()\"))\n",
        "\n",
        "create_folium_map('/tmp/predictions.geojson',pathgcp_imagebefore, pathgcp_imageafter)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WXVMbL_PclUV"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
